\documentclass[10pt, conference, letterpaper]{IEEEtran}
\usepackage{cite}
\usepackage{xcolor,soul,framed}
\usepackage{amsmath,amsthm,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{color, soul}
\usepackage{algorithm, algorithmic}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{mathtools}
\graphicspath{ {./images/} }

%---------------------------------------------------------------%
\newtheorem{definition}{Denifition}
\newtheorem{assumption}{Assumption}
\newtheorem{problem}{Problem}
\newtheorem{lemma}{Lemma}
\newtheorem{remark}{Remark}
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}
\newtheorem{example}{Example}
\newcommand{\eq}{=}
\newcommand{\domZ}{\mathbb{Z}_{*}}
\newcommand{\vecOne}{\mathbf{1}}
\newcommand{\ind}{\mathbf{I}}
\newcommand{\mat}{\mathbf}
\newcommand{\define}{\triangleq}
\newcommand{\leadto}{\Rightarrow}
\renewcommand{\vec}{\mathbf}
\DeclarePairedDelimiter{\set}{\{}{\}}
\DeclarePairedDelimiter{\norm}{|}{|}
\DeclarePairedDelimiter{\Inorm}{\|}{\|_1}
\DeclarePairedDelimiter{\Paren}{\bigg(}{\bigg)}
\DeclarePairedDelimiter{\Bracket}{\bigg[}{\bigg]}
\DeclarePairedDelimiter{\Brace}{\bigg\{}{\bigg\}}
%---------------------------------------------------------------%
\newcommand{\apSet}{\mathcal{K}}
\newcommand{\esSet}{\mathcal{M}}
\newcommand{\jSpace}{\mathcal{J}}
\newcommand{\wSet}{\mathcal{W}}
\newcommand{\uSet}{\mathcal{U}}
\newcommand{\cSet}{\mathcal{C}}
\newcommand{\Stat}{\mathbf{S}}
\newcommand{\Obsv}{\mathcal{Y}}
\newcommand{\Policy}{\mathbf{\Omega}}
%---------------------------------------------------------------%

\begin{document}

    %=============================== TITLE ===============================%
    \title{
        Meet-in-Future: Distributed Online Job Dispatching with Obsolete Information in Edge Computing System
    }
    \author{
        \IEEEauthorblockN{
            Yuncong Hong\IEEEauthorrefmark{1}\IEEEauthorrefmark{2},
            % Rui Wang\IEEEauthorrefmark{1},
            % Haisheng Tan\IEEEauthorrefmark{3},
            % Francis C.M. Lau\IEEEauthorrefmark{2}
        }
        \IEEEauthorblockA{
            \IEEEauthorrefmark{1}Southern University of Science and Technology, P.R. China,
            \IEEEauthorrefmark{2}The University of Hong Kong, Hong Kong,\\
            \IEEEauthorrefmark{3}University of Science and Technology of China, P.R. China
        }
    }
    \maketitle

    %============================== ABSTRACT ==============================%
    \begin{abstract}
        \label{sec:abstract}
        Edge computing is believed to be the solid solution for time-sensitive big data real-time calculation. The cooperation among edge servers in the same system usually causes ineffective task scheduling due to obsolete information sharing, which is hard to tackle even with extra centralized agent design. In this work, we formulate the problem with job dispatching in distributed Edge Computing system, and identify the difficulty exists in cooperation between AP nodes (Access Points) and ES nodes (Edge Servers) with delayed information. We design the broadcast information in the system and formulate the corresponding problem into a MDP problem. The value function approximation and one-step policy iteration method is adopted to obtain a sub-optimal dispatching policy whose performance can be bounded analytically.
    \end{abstract}

    % \begin{IEEEkeywords}
    %     Edge Computing, Job Dispatch, Delayed Information, Collective Observability, Distributed Multi-agent MDP
    % \end{IEEEkeywords}

    %============================ INTRODUCTION ============================%
    \begin{section}{INTRODUCTION}
        \label{sec:introduction}
        Our claims:
        \begin{itemize}
            \item Related works on job dispatching on scheduling in edge computing, mostly with centralized agent to apply action and seldomly take delayed information impact into consideration;
            \item Edge Server, Access Point, User Equipment; layered structure where decision is made distributedly on AP nodes and computation is carried out on ESs; The AP-ES fully separated structure is reasonable, for example C-RAN to separate communication and computation resource assembling;
            \item We identify the delayed system information is un-acceptable for explosion \emph{delay-sensitive jobs} in edge computing, and it's hard to establish cooperation among AP nodes because of obsolete information;
            \item information sharing for cooperation is designed via (aligned) broadcast, job dispatch decision should be made immediately based on the previous collective information;
        \end{itemize}

        Our contributions:
        \begin{itemize}
            \item identify that the uploading process affect the performance of heuristic greedy algorithm; identify that the delay-information sharing in decision making;
            \item propose a instantaneous job dispatching scheme in a fully-distributed cooperative way;
            \item propose global state formulation to characterize the multi-agent MDP problem;
            \item adopt value function approximation to reduce the traditional algorithm complexity, and come up with distributed online learning algorithm;
        \end{itemize}

        Related works:
        \begin{itemize}
            \item The earliest related works we find is \cite{ref-01} (cited 167 times). In this work, the single agent is assumed not able to observe the global state, and thus they need communication to establish cooperation by sharing \emph{information}. The agent considers communication as extra action to synchronize the states and thus incurs extra cost. \\
            However, the communication is without delay, and converted into POMDP problem.
            \item The other work \cite{ref-02} considers continuous state observation with constant or stochastic delay with single agent.
        \end{itemize}

        Bulky Reference List for Journals:
        \begin{itemize}
            \item \text{[IoT, out-of-date information]} \cite{Lyu2017} is work considering \emph{out-of-date knowledge} optimization in IoT computing scenario, with Lyapunov optimization;
            \item \text{[out-of-date information]} \cite{Lyu2018b} 
            \item \text{[IEEE Access, baseline]} \cite{Fan2017} considers cooperations of multiple MEC-BSs of computation offloading which minimizes total cost of time and energy consumptions.
            \item \text{[delay-sensitive, ToC]} \cite{Lyu2018} identify that task admission is critical to delay-sensitive applications in mobile edge computing, and proposes an (1-$\epsilon$)-approximation algorithm
            \item \text{[foggy, fully distributed online]} \cite{Lyu2018a} is a work fully distributed online optimization to minimize the time-average cost and achieve asymptotic optimality over infinite time;
            \item \text{[online learning, multi-agent MDP, reduced state]} \cite{Zheng2019} is a work considering maximizing the long-term utility in MEC offloading policy, and formulating the problem with MDP solved with Q-learning (however the baseline policy compared is too naive);
            \item \text{[MDP, IEEE ToN]} \cite{Wang2015} considers service migration with MDP with approximate states;
            
            \item \text{[system work, ToMC]} \cite{Yu2018} is a work presents a framework to minimize remote execution overhead, and carry out real system experiments using large-scale data from cellular network provider.
            \item \text{[system work, MDP, IEEE Access]} \cite{Wang2018} considers the mobility of mobile users in limited coverage solved with service migration and handover, and propose a framework;
            
            \item \text{[offloading and resource allocation]}
                \cite{Yang2016} is a work considering services placement and requests dispatching on edge servers, and leverage users' pattern to predict "service cache" for online decision making;
                \cite{Du2018} is a work considering computation offloading and computation resource allocation to satisfy min-max fairness guarantee, under minimum tolerant delay;
                \cite{Chen2018} is a work with SDN on task offloading and battery life saving, and solve the NLP problem with two sub-problems;
                \cite{Alameddine2019} is a work considering task offloading, scheduling and resource allocation joint optimization with Benders Decomposition;

            \item \text{[Survey]}
                \cite{Naha2018} is a survey about fog computing in latency-aware computing in IoT, and investigate numerous proposed computing architecture.
            
            \item \text{[misc]}
                \cite{Chen2016} is a work considering multi-user computation offloading with multi-channel contention, and adopt game theory approach to achieve Nash equilibrium with upper bound of convergence time;
                \cite{Josilo2019} considers selfish offloading to achieve Nash equilibrium;
                \cite{Rodrigues2017} is a work on minimizing service delay in mobile edge computing;
                \cite{Wang2017} is a work considering service placement with graph theory;
                \cite{Masip-Bruin2016} is a work with layered structure with foggy and cloud computation;
                \cite{Zhang2018} considers multi-user offloading under transmit power decision and user association decision;
                \cite{Chen2018a} proposes joint optimization of task caching placement and offloading decision to achieve the lowest delay of task processing;
                \cite{Dinh2018} considers distributed multi-user offloading in wireless channel with selfish EPG (exact potential game);
                \cite{Guo2018} considers jointly offloading decision making and power allocation for UEs in SCNs (small-cell networks);
                \cite{yang2018} and \cite{Josilo2019a} considers distributed computation offloading game;
                \cite{ElHaber2019} is a work considers energy consumption for offloading in multi-tier edge clouds;
                \cite{Liu2018} is a work considering minimize users' power consumption with Lyapunov optimization and matching theory;
        \end{itemize}

    \end{section}

    %============================ SYSTEM MODEL ============================%
    \begin{section}{SYSTEM MODEL}
        \label{sec:model}
        \begin{subsection}{Network Model}
            We have access points (AP) and edge servers (ES) denoted as $\apSet \define \set{1,\dots,K}$ and $\mathcal{M} \define \set{1,\dots,M}$ respectively in our MEC (mobile edge computing) system depicted in Fig. \ref{fig:system}. In this system, we adopt the same timing mechanism at both AP and ES side with a minimum \emph{timeslot} lasting for $\tau$ seconds.

            \begin{figure}[ht]
                \centering
                \includegraphics[width=0.45\textwidth, trim={0.5cm 0.5cm 0.5cm 0.5cm}, clip]{system-model.pdf}
                \caption{The Illustration of MEC System Model}
                \label{fig:system}
            \end{figure}

            The user equipment (UE) is connected to AP and offloads computation jobs to access point. Thus the job arrival process on $k$-th AP ($\forall k\in\apSet$) is compounded of job-arrival distribution and job-type distribution from all the UEs connected, which follows the assumption as:
            \begin{assumption}[Job Arrival Process for AP]
                The job arrival distribution for $k$-th AP is denoted as $A_k$, which is i.i.d over each timeslot as $A_k \sim Bernoulli(\lambda_k)$. This implies that there will be at most one job arrives on $k$-th AP in one timeslot. According to \emph{Poisson Limit Theorem}, the arrival process is a memory-less exponential process with average arrival rate $\mathbb{E}[A_k]=\lambda_k$.
                \\
                The jobs type distribution on each AP node follows the same distribution over job set $\jSpace$ which is denoted as $p_j \define \Pr\{j\}, \forall j\in\jSpace$.
            \end{assumption}

            The AP itself is assumed with no computation capability, and thus it need to further dispatch those jobs to the edge servers.
            The offloaded jobs on AP will be immediately dispatched to edge servers in each timeslot. The corresponding uploading delay of one job is deterministic and job-type independent for one AP-ES link, which is denoted as $u_{k,m}$ from $k$-th AP to $m$-th ES ($\forall k\in\apSet, \forall m\in\esSet$).
            The network topology between AP cluster and ES cluster is fully accessible so that AP could dispatch jobs to any ES nodes in this system.

            After arrival on edge servers, the jobs will join computation with the supported VM (Virtual Machine).
            For jobs computation on edge servers, we adopt \emph{unrelated machines} assumption in \cite{tan-online}, where the job processing time on different servers are machine dependent and variant of resource or VM (virtual machine) constraints.
            The maximum job processing time is bounded with $L_C$ in this system, and the job space is denoted as $\jSpace$. Moreover, we have the mapping function $f:\jSpace \to \domZ^M$ to store \textcolor{red}{deterministic processing time vector} for different jobs. For convenience, we assign infinity processing time for the type of jobs on edge servers which have no VM resource available, and this kind of dispatching possibility will be rejected at the AP side.
            Each VM is considered running parallelled without resource contention, and the job scheduling for each VM follows \emph{FCFS} (First-Come-First-Serve).
        \end{subsection}

        \begin{subsection}{Information-Sharing Broadcast Model}
            As there is no centralized agent design to distribute the dispatching decision to each AP nodes, all the AP nodes have to collect the global information from other nodes. Therefore, a information sharing scheme is needed to facilitate efficient cooperation among standalone AP nodes with dispatching decision.
            The sharing is designed via periodic broadcasting, where all the AP and ES nodes in the system should broadcast their system related information with a same period interval as $t_B$. More specifically, the broadcasting is applied in a synchronized way that all the nodes start to broadcast at the start of same timeslot and repeat broadcasting after the same periodic interval $t_B$. We call each periodic point of broadcasting as \emph{broadcast point} and denote the $i$-th broadcast with $t_i$ where,
            \begin{align}
                t_i = i \cdot t_B, i=0,1,2,\dots
            \end{align}
            
            For $i$-th \emph{broadcast point}, the composed broadcast information from all the AP and ES nodes, and the corresponding information is listed as following:
            \begin{itemize}
                \item The $k$-th AP ($\forall k\in\apSet$) contains $\mat{R}_k(i) \define [r^{(k)}_{m,j}(i)], \forall m\in\esSet, \forall j\in\jSpace$, where $r^{(k)}_{m,j}(i)$ denotes the remaining number of $j$-type jobs in uploading to $m$-th ES at time $t_i$; and we have $\vec{r}^{(k)}_{m}$ to denote the rows in $\vec{R}_k(i)$ and $\vec{\hat{r}}^{(k)}_{j}$ to denote the columns;
                \item The $m$-th ES ($\forall m\in\esSet$) contains information $\vec{Q}_m(i) \define \set{Q_{m,j}(i)|\forall j\in\jSpace}$ to denote the computation queues for different job types, where $Q_{m,j}(i)$ is composed of pair $(n_{m,j}(i), \delta_{m,j}(i))$ to characterize the FIFO queue; $n_{m,j}(i)$ denotes the number of $j$-type job queueing on $m$-th ES, and $\delta_{m,j}(i)$ denotes the remaining processing time for last job.
            \end{itemize}
            Thus the composed broadcasting information is denoted as:
            \begin{align}
                \Obsv_i \define
                        \Brace{
                            \set{\mat{R}_{k}(i)|\forall k\in\apSet},
                            \set{\vec{Q}_m(i)|\forall m\in\esSet}
                        },
            \end{align}
            where $\Obsv_i$ is a set of global information of $i$-th broadcast. And it's actually the global system states at $t_i$.

            After the broadcast point $t_i$, different AP nodes will receive the broadcast information from AP nodes or ES nodes with different deterministic delay.
            Let $d^{(p)}_{k,k'}$ denotes the broadcast delay from $k'$-th AP to $k$-th AP ($\forall k,k'\in\apSet$) w.r.t. the last broadcast point; let $d^{(s)}_{k,m}$ denotes the broadcast delay from $m$-th ES to $k$-th AP ($\forall k\in\apSet,\forall m\in\esSet$). We furthermore call the delay when the AP node could receive all the broadcast information happened at $t_i$ as \emph{maximum broadcast delay}, which is defined as following:
            \begin{definition}[Maximum Broadcast Delay]
                \begin{align}
                    \hat{d}_k = \max \Paren{\set{d^{(p)}_{k,k'}|\forall k,k'\in\apSet}, \set{d^{(s)}_{k,m}|\forall k\in\apSet,m\in\esSet}},
                \end{align}
                where $d^{(p)}_{k,k} \equiv 0$ for convenience. The AP nodes will receive the complete broadcast information about the system only after its corresponding maximum broadcast delay with respect to last broadcast point.
            \end{definition}

            \textcolor{red}{The broadcast design introduces a \emph{Two-time scale} structure in the MEC system. The job dispatching on AP nodes and scheduling on ES nodes are still carried out based on timeslot scale. However, based on the broadcast period, the uploading process and computing process is separated into consideration.
            More specifically, the uploaded jobs in current broadcast interval will keep waiting on edge servers; at the end of this broadcast interval (just before next broadcast point), the uploading jobs will join the queue on servers for scheduling. This separated process assumption will alleviate the curse of dimensionality in problem formulation, which considers the uploading process not entangled with computation process.
            Moreover, it's reasonable to assume that the broadcast interval is always larger than any broadcast delay plus the uploading delay for any AP nodes, i.e. $t_B > \hat{d}_{k} + u_{k,m}$ $(\forall k\in\apSet, \forall m\in\esSet)$.}
        \end{subsection}
    \end{section}

    %============================ FORMULATION =============================%
    \begin{section}{PROBLEM FORMULATION}
        \label{sec:formulation}
        In this section, we formulate the standard MDP problem with respect to the broadcast-point time scale. The formulated problem is based on global information shared via synchronized broadcast, and the the optimal solution is achieved via compounded dispatching policies on all AP nodes.
        Given the fact that AP nodes would obtain global states update only after \emph{maximum broadcast delay} in each broadcast interval, the formulated MDP problem is composed of two adjacent broadcast interval with obsolete information and updated information.
        Then we show that the solution for all AP nodes suffers from curse of dimensionality and a low-complexity solution is needed.

        \begin{subsection}{System State and Dispatching Policy}
            The system states is selected based on the nature that $k$-th AP comes up with complete broadcast information only after its corresponding \emph{maximum broadcast delay} in the broadcast interval.
            The relative difference between broadcast point and the maximum delay point is depicted in Fig. \ref{fig:br-trans} \hl{(need to modify the state denotation in figure)}.
            \begin{definition}[System State]
                The system state at $i$-th broadcast point is denoted as $\Stat_i \define (\Obsv_{i}, \Obsv_{i-1}), (i=1,2,\dots)$, where $\Obsv_{i-1}$ represents the obsolete information before the broadcast received, and $\Obsv_{i}$ represents the updated information after the corresponding $\hat{d}_k$ delay for $k$-th AP node.
            \end{definition}

            \begin{figure}[ht]
                \centering
                \includegraphics[width=0.45\textwidth]{broadcast-trans.png}
                \caption{Global Consensus and Transition with Delayed Action}
                \label{fig:br-trans}
            \end{figure}

            The \emph{dispatching policy} is applied over arrival jobs in each timeslot on each AP, and the \emph{dispatching action space} is defined as $\vec{a}: (j, m) \in \jSpace \times \esSet$, where $(j, m)$ denotes the action that $j$-type job should be uploaded to $m$-th ES. Based on the two stages of global system information $\Obsv_{i-1}$ and $\Obsv_{i}$ in system state, the compounded global-wise policy of all AP nodes is defined as following:
            \begin{definition}[Compounded Dispatching Policy]
                The compounded dispatching policy over $\Stat_{i}$ is defined as $\Policy(\Stat_{i})$ which is composed of all the local policies $\Omega_k(\Stat_{i})$ ($\forall k\in\apSet$) as:
                \begin{align}
                    \vec{\Omega}(\Stat_{i}) \define \Bracket{\Omega_1(\Stat_{i}), \dots, \Omega_K(\Stat_{i})}
                \end{align}
                More specifically, $\Omega_k(\Stat_{i})$ is composed of two-stage policy as:
                \begin{align}
                    \Omega_k(\Stat_i) = [\tilde{\Omega}_k(\Obsv_{i-1}), \tilde{\Omega}_k(\Obsv_{i})],
                    % $t\in[t_{i-1}, t_{i}], \Delta{t} \define t - t_{i-1}$
                \end{align}
                where $\tilde{\Omega}_k(\Obsv_{i}) \define \set{\omega^{(i)}_{k,m}(j)|\forall j\in\jSpace, \forall m\in\esSet}$ and $\omega^{(i)}_{k,m}(j)$ denotes the dispatching policy that: based on global information $\Obsv_{i}$, the stochastic action on $k$-th AP upload $j$-type job to $m$-th ES ($\sum_{j\in\jSpace} \Pr\{\omega^{(i)}_{k,m}(j)\}=1$).
            \end{definition}
            More specifically, the two phase of the policy on single AP is separated by the \emph{maximum broadcast delay} $\hat{d}_k$ to $k$-th AP, i.e. the time point when it receives the latest global information. For example, in the broadcast interval $[t_{i}, t_{i+1}]$, $k$-th AP will apply policy $\tilde{\Omega}_k(\Obsv_{i})$ based on obsolete information before maximum delay $\hat{d}_k$ and apply $\tilde{\Omega}_k(\Obsv_{i+1})$ immediately after the delay.
        \end{subsection}

        \begin{subsection}{The Optimization Problem}
            The optimization target of our problem is to minimize the \emph{average response time} of all jobs, which is composed of uploading time from AP to ES, and queueing-and-service time on ES nodes. According to \emph{Little's Law}, the average response time of all the jobs is equally as average number of jobs in system. Therefore, based on the system state definition, we have cost function as:
            \begin{align}
                g \bigg( \Stat_{i}, \Policy(\Stat_{i-1}) \bigg) \define
                        \sum_{k\in\apSet}\sum_{m\in\esSet} \Inorm{\vec{r}^{(k)}_{m}} +
                        \sum_{m\in\esSet}\sum_{j\in\jSpace} n_{m,j}(i),
            \end{align}
            where $\Inorm{\vec{r}^{(k)}_{m}}$ denotes the l1-norm of vector $\vec{r}^{(k)}_{m}$, i.e. the sum up of absolute value of each entry. The cost function defined is a sampling of interval $t_B$ over the whole process, because the global information for AP nodes only contains the information at the broadcast points.

            Our distributed optimization problem definition is given as following:
            \begin{problem}[Distributed Cooperative Job Dispatching Problem]
                \begin{gather}
                    \min_{\Policy} \lim_{T \to \infty}
                        \mathbb{E}_{\Policy, \{A_k(t)|\forall k\in\apSet\}}
                            \Bracket{\sum_{i=2}^{T} \gamma^{i-1} g(\Stat_{i}, \Policy(\Stat_{i-1}))|\Stat_1},
                \end{gather}
                where the cost is collected with a discount factor $\gamma$.
            \end{problem}

            According to \cite{sutton1998introduction}, the above problem could be solved by the following \emph{Bellman's equation}:
            \begin{align}
                V(\Stat_{i}) =& g(\Stat_i) + \gamma \min_{\Policy(\Stat_{i})} \sum_{\Stat_{i+1}} \Pr\{ \Stat_{i+1}|\Stat_{i}, \Policy(\Stat_{i}) \} V(\Stat_{i+1}),
            \end{align}
            where the original definition for value function defined in \cite{sutton1998introduction} is as following:
            \begin{align}
                V(\Stat_{i}) \define \lim_{T\to\infty}
                    \mathbb{E}_{\Policy}\Bracket{
                        \sum_{l=0}^{T} \gamma^l g\Paren{\Stat_{i+l}, \Policy(\Stat_{i+l-1})}
                    }
            \end{align}

            Before diving into the analysis on the transition function expression, we firstly come up with some probability denotations.
            The job arrival processes for AP nodes under dispatching policy compose the job arrival process for ES nodes, which could be expressed as compounded of \emph{numbers arrival distribution} and \emph{length arrival distribution} for $j$-type job ($\forall j\in\jSpace$).
            \begin{itemize}
                \item The \emph{numbers arrival distribution} on $m$-th ES is composed of i.i.d Bernoulli distribution in each timeslot from independent AP nodes. The PMF (probability mass function) of the Bernoulli distribution from $k$-th AP under policy $\Omega_k(i)$ is denoted as:
                \begin{align}
                    p_{k,m}^{(\lambda,i)}(j) \define& \lambda_k
                        \frac{
                                p(j) \cdot \Pr\{\omega_{k,m}^{(i)}(j)\}
                            }{
                                |\jSpace|
                            }
                %     \\
                %     p_{k,m}^{(\lambda,i)} \define& \sum_{j\in\jSpace} p_{k,m}^{(\lambda,i)}(j),
                \end{align}
                where $|\jSpace|$ denotes the cardinality of job space to function as normalization factor; and we have $p_{k,m}^{(\lambda, \Pi_k)}$ denotes the distribution under time-invariant policy $\Pi_k$ for $k$-th AP;
                \item The \emph{length arrival distribution} on $m$-th ES from $k$-th AP under policy $\Omega_k(i)$ is denoted as:
                \begin{align}
                    p_{k,m}^{\theta,i}(j) = p(j) \cdot \Pr\{\omega_{k,m}^{(i)}(j)\} \cdot 
                \end{align}
            \end{itemize}
            
            \begin{lemma}[Transition Function Decoupling]
                The transition function in Bellman's equation could be decoupled to facilitate the final approximated value function expression. The transition function could be decoupled as:
                \begin{align}
                    & \Pr\{\Stat_{i+1}|\Stat_{i}, \Policy(\Stat_{i})\} 
                    \nonumber\\
                    =& \prod_{k\in\apSet} \Pr\Brace{\vec{n}_k(i+1)|\Policy(\Stat_{i})} \times
                        \nonumber\\
                        & \prod_{m\in\esSet}
                            \Pr \Brace{Q_m(i+1)|Q_m(i), \set{\vec{n}_k(i)|\forall k\in\apSet}, \Policy(\Stat_{i})},
                \end{align}
                where first production part denotes the unfinished uploading state transition for AP nodes whose distribution, and the second part denotes the queueing state transition for ES nodes.
            \end{lemma}
            \begin{proof}
                Please refer to appendix \ref{trans-decouple}.
            \end{proof}

            As the formulated problem above is of infinite states and the action space would be exponentially expanded with respect to number AP and ES nodes, we could not use traditional \emph{policy iteration} or \emph{value iteration} algorithm \cite{sutton1998introduction} for unacceptable computational complexity. To alleviate curse of dimensionality, we take baseline dispatching policy to approximate the value function for each AP and ES nodes, and then carry out one-step iteration to obtain a better value function approximation.
        \end{subsection}
    \end{section}

    %============================= ALGORITHM ==============================%
    \begin{section}{LOW-COMPLEXITY SOLUTION}
        \label{sec:algorithm}
        In this section, we introduce a heuristic dispatching algorithm as the baseline policy, whose value function could be derived analytically. Then the joint expression with transition function as the optimization problem on right-hand side, we could further reduce the state complexity with averaged queueing dynamics on ES nodes.
        \hl{The proposed low-complexity suboptimal policy can be obtained via the above approximated value function and one-step policy iteration. The derived value function becomes the cost upper bound of the proposed policy.}

        \begin{subsection}{Baseline Dispatching Policy}
            The baseline dispatching policy is adopted to obtain an approximation of value function. The policy on each AP nodes is randomized and time-invariant which is denoted as:
            \begin{align}
                \vec{\Pi} \define \Bracket{\Pi_1, \Pi_2, \dots, \Pi_K},
            \end{align}
            where $\Pi_k \define \set{\omega_{k,m}(j)|\forall m\in\esSet,\forall j\in\jSpace}$, $\forall k\in\apSet$.

            According to the linear property of cost function, the value function could be divided linearly into two section as $\tilde{W}^{(p)}(\Obsv^{(p)}(i))$ and $\tilde{W}^{(s)}(\Obsv(i))$ under baseline policy:
            \begin{align}
                V(\Stat_{i}) =& 
                    g(\Stat_{i}) + \gamma \min_{\Policy(\Stat_{i})} \sum_{\Stat_{i+1}} \Pr\{ \Stat_{i+1}|\Stat_{i}, \Policy(\Stat_{i}) \}
                    \nonumber\\
                    & \cdot \Bracket{ \tilde{W}^{(p)}\Paren{\Obsv^{(p)}(i+1)} + \tilde{W}^{(s)}\Paren{\Obsv(i+1)} },
            \end{align}
            where $\tilde{W}^{(p)}(\cdot)$ and $\tilde{W}^{(s)}(\cdot)$ denote the split value function over AP nodes and ES nodes respectively; $\Obsv^{(p)}(i) \define \set{\vec{n}_k(i)|\forall k\in\apSet}$ and $\Obsv^{(s)}(i) \define \set{\vec{Q}_m(i)|\forall m\in\esSet}$ respectively denote the AP states collection and ES states collection for $\Obsv(i) = \Obsv^{(p)}(i) \cap \Obsv^{(s)}(i)$, and the split value function is in the following form:
            \begin{align}
                &\tilde{W}^{(p)}\Paren{\Obsv^{(p)}(i)} \define \sum_{k\in\apSet}
                    \mathbb{E}_{\Pi}\Bracket{\sum_{l=0}^{\infty} \gamma^{l} \Inorm{\vec{n}_k(i+l)}}
                \\
                &\tilde{W}^{(s)}\Paren{\Obsv(i)} \define \sum_{m\in\esSet} \sum_{j\in\jSpace}
                    \mathbb{E}_{\Pi}\Bracket{\sum_{l=0}^{\infty} \gamma^{l} |Q_{m,j}(i+l)|}
            \end{align}
            The decoupled value functions for AP and ES nodes is obtained with an approximated form under the baseline policy.

            The approximated value function $\tilde{W}^{(p)}(\Obsv^{(p)}(i+1))$ for AP nodes is obtained as:
            \begin{align}
                \tilde{W}^{(p)}(\Obsv^{(p)}(i+1))
                = \frac{1}{1-\gamma} \sum_{k\in\apSet} \mathbb{E}_{\Pi_k}[\Inorm{\vec{n}_k}],
            \end{align}
            where the expectation of $\Inorm{\vec{n}_k}$ under the policy $\Pi_k$ is actually a constant as expectation of Binomial distribution $\mathbb{E}_{\Pi_k}[\Inorm{\vec{n}_k}] = u_{k,m} p^{(\lambda, \Pi_k)}_{k,m}$.
            
            The approximated value function $\tilde{W}^{(s)}(\Obsv(i))$ for ES nodes is affected with both arrival process under dispatching policy and last queue state, and we reduce the states expression by averaging the uploading process together with the transition function expression.
            % For convenience, we have $\Obsv^{(p)}(i) \define \set{\vec{u}_k(i)|\forall k\in\apSet}$ and $\Obsv^{(s)}(i) \define \set{Q_m(i)|\forall m\in\esSet}$.
            The partial value function optimization for ES in Bellman's Equation right-hand side is given as:
            \begin{align}
                \min_{\Policy(\Stat_i)}& \sum_{\Stat_{i+1}}
                    \Pr\Brace{\Stat_{i+1}|\Stat_{i}, \Policy(\Stat_i)} \cdot \tilde{W}^{(s)}\Paren{\Obsv(i+1)}
                \nonumber\\
                % \leadto \min_{\Policy(\Stat_i)}& \sum_{\Obsv^{(s)}(i)} \Pr\{\Obsv^{(s)}(i+1)|\Obsv^{(s)}(i),\Obsv^{(p)}(i), \Policy(\Stat_i)\}
                %     \nonumber\\
                %     & \times \sum_{\Obsv^{(p)}(i)} \Pr\{\Obsv^{(p)}(i+1)|\Policy(\Stat_i)\} \cdot \tilde{W}^{(s)}(\Obsv(i+1))
                % \nonumber\\
                \leadto \min_{\Policy(\Stat_i)}& \sum_{\Obsv^{(s)}(i)}
                    \Pr\Brace{\Obsv^{(s)}(i+1)|\Obsv^{(s)}(i), \Obsv^{(p)}(i), \Policy(\Stat_i)}
                    \nonumber\\
                    \times& \sum_{m\in\esSet} \sum_{j\in\jSpace}
                        \mathbb{E}_{\Obsv^{(p)}(i+1)|\Policy(\Stat_i)}\Bracket{\tilde{W}^{(s)}_{m,j}\Paren{\Obsv(i+1)}}
            \end{align}
            Let $\tilde{V}^{\Policy(\Stat_i)}(Q_{m,j}(i+1)) \define \mathbb{E}_{\Obsv^{(p)}(t+1)|\Policy(\Stat_t)} [\tilde{W}^{(s)}_{m,j}(\Obsv(i+1))]$ denotes the averaged value function for $m$-th ES node, which implies that the state $\Obsv^{(p)}(i)$ is substitute with its expectation under policy $\Policy(\Stat_i)$ in this value function.

            Furthermore, the approximated value function could be rewrite with reduced states for stationary FCFS process as $\tilde{V}^{\Policy(\Stat_i)}(\tilde{Q}_{m,j}(i+1))$, where $\tilde{Q}_m(i+1) \define [N_{m,j}(i+1), r_{m,j}(i+1)]$, $N_{m,j}(i+1)$ denotes the number of $j$-type jobs queue on $m$-th ES and $r_{m,j}(i+1)$ denotes the remaining time of last unfinished $j$-type job. Thus the approximated value function for $m$-th ES node is denoted as:
            \begin{align}
                \tilde{V}\bigg(\tilde{Q}_{m,j}(i+1)\bigg) \define& \lim_{T\to\infty}
                    \mathbb{E}_{\vec{\Pi}} \Bracket{\sum_{l=0}^{T} \gamma^{l} N_{m,j}(i+l+1)}
                \nonumber\\
                % =& \vec{u}'_i [\lim_{T\to\infty} \sum_{n=0}^{T} (\gamma \mat{P}_m)^{n}] \vec{g}_q
                % \nonumber\\
                =& \vec{\mu}'_i \Paren{\mat{I} - \gamma \mat{P}_m}^{-1} \vec{g}_q,
            \end{align}
            where $\vec{\mu}'_i$ denotes the transpose of $\vec{\mu}_i$, and $\vec{\mu}_i = [0,\dots,0,1,\dots]$ with only $i$-th element as $1$; the $i$-th element of $\vec{g}_q$ denotes the cost of server as $N_m(i)$ for $i$-th stage; $\mat{P}_m$ denotes the transition matrix under the policy $\vec{\Pi}$ which is composed of the following transition function ($\forall \tilde{Q}_m(i),\tilde{Q}_m(i+1)$) as:
            \begin{align}
                & \Pr \Brace{\tilde{Q}_m(i+1)|\tilde{Q}_m(i),\vec{\Pi}}
                \nonumber\\
                % =& \Pr\{\begin{pmatrix}
                %     N_m(i+1) \\ r_m(i+1)
                % \end{pmatrix}|\begin{pmatrix}
                %     \tilde{N}_m(i+1) \\ r_m(i)
                % \end{pmatrix}\}
                % \nonumber\\
                =& \prod_{k\in\apSet} \Pr\{\tilde{N}^{(k)}_m(i)\} \prod_{n=0}^{\tilde{n}_0 + \tilde{N}^{(k)}_m(i)} p^{(\theta,\Pi_k)}_{k,m}(j_{k,n})
                    \nonumber\\
                    &\times I[\tilde{N}^{(k)}_m(i) = N^{(k)}_m(i+1)- \tilde{n}_0]
                    \nonumber\\
                    &\times I[\sum_{j_{k,n}} f(j_{k,n})^{(m)} = r_m(i+1)+t_B-r_m(i)],
            \end{align}
            where:
            \begin{itemize}
                \item $f:\jSpace \to \domZ^M$ is the mapping function from job-type index to job processing time vector of all servers, and $f(j)^{(m)}$ denotes the $m$-th entry of $j$-type job;
                \item $\tilde{n}_0 = t^{(u)}_{k,m}p^{(\lambda,i)}_{k,m}$ is the averaged $\Obsv^{(AP)}$ state under policy $\Policy(\Stat_i)$;
                \item $\tilde{N}^{(k)}_m(i) \sim Bin(t_B-t^{(u)}_{k,m}, p^{(\lambda, \Pi_k)}_{k,m}), (\forall k\in\apSet)$.
            \end{itemize}
        \end{subsection}

        \begin{subsection}{The Distributed Algorithm}
            The approximate Bellman's equation under baseline policy is denoted as:
            \begin{align}
                % V(\Stat_i) = &g(\Stat_i) +
                % \nonumber\\
                \min_{\Policy(\Stat_i)}& \sum_{\Obsv^{(s)}(i+1)} \Pr\{\Obsv^{(s)}(i+1)|\Obsv^{(s)}(i), \Obsv^{(p)}(i), \Policy(\Stat_i)\}
                \nonumber\\
                \times \bigg[& \sum_{m\in\esSet} \tilde{V}^{\Policy(\Stat_i)}\bigg(\tilde{Q}_m(i+1)\bigg) +
                    \nonumber\\
                    & \underbrace{\sum_{\Obsv^{(p)}(i+1)} \Pr\{\Obsv^{(p)}(i+1)|\Policy(\Stat_i)\}}_{\text{Expectation of Binomial}|\Policy(\Stat_i)}
                    \cdot \underbrace{\tilde{W}^{(p)}\bigg(\Obsv^{(p)}(i+1)\bigg)}_{\text{constant}} \bigg]
            \end{align}
            Then we introduce the one-step iteration algorithm:
            % [\IF, \ENDIF], [\FOR, \TO, \ENDFOR], [\WHILE, \ENDWHILE], \STATE, \AND, \TRUE
            \begin{algorithm}[H]
                \caption{Distributed Algorithm for $k$-th AP}
                \begin{algorithmic}
                    \WHILE{\TRUE}
                        \STATE (in progress ...)
                        % \FOR{$k \in \mathcal{K}$}
                        %     \STATE fix policy $\vec{\Omega}^{(k)}(t) \forall k' \neq k$
                        % \ENDFOR
                    \ENDWHILE
                \end{algorithmic}
            \end{algorithm}
        \end{subsection}
        
    \end{section}

    %============================ EVALUATION ==============================%
    \begin{section}{EVALUATION}
        \label{sec:evaluation}
        (in progress ...)
    \end{section}

    %============================= CONCLUSION =============================%
    \begin{section}{CONCLUTION}
        \label{sec:conclusion}
        (in progress ...)
    \end{section}
    
    %============================== APPENDIX ==============================%
    \appendices

    \begin{section}{Transition Function Decoupling}
        \label{trans-decouple}

        The first production part is given as:
        \begin{align*}
            \Pr\{\vec{u}_k=\vec{u}|\Policy(\Stat_i)\} \sim \prod_{m\in\esSet}
                Bin\Paren{t^{(u)}_{k,m}-1,p^{(\lambda, i)}_{k,m}},
        \end{align*}
        where $Bin(n,p)$ denotes a Binomial distribution.
            
        The second part transition function is rather complex and composed of three independent distribution as depicted in Fig. \hl{(need a timeline graph)}. We denote the state $Q_m(i+1)$ over the three stages as:
        \begin{align*}
            Q_m(i+1) = [\tilde{Q}_m(i), Y_0, Y_1, Y_2],
        \end{align*}
        where $\tilde{Q}_m(i)$ denotes the remaining part of the previous $Q_m(i)$ after $t_B$ timeslots computing in $[t_{i}, t_{i+1}]$, and:
        \begin{itemize}
            \item $Y_0$ denotes the enqueued job set from unfinished uploading jobs in last interval as $\set{u_{k,m}(i)|\forall k\in\apSet}$, where $n^{(k)}_0 \define u_{k,m}(i)$, $|Y_0|=\sum_{k\in\apSet} u_{k,m}(i)$;
            \item $Y_1$ and $Y_2$ respectively denotes the enqueued job set uploaded by all AP nodes under policy $\omega_{k,m}^{i-1}$ and $\omega_{k,m}^{i}$, where $|Y_1|\define\sum_{k\in\apSet}N^{(k)}_1, |Y_2|\define\sum_{k\in\apSet}N^{(k)}_2$.
        \end{itemize}
        Then we have the transition function for $m$-th ES node given as:
        \begin{align*}
            & \Pr\Brace{Q_m(i+1)|Q_m(i), \set{\vec{u}_k(i)|\forall k\in\apSet}, \Policy(\Stat_i)}
            \nonumber\\
            =& \Pr\Brace{\tilde{Q}_m(i)|Q_m(i)}
                \Pr\Brace{Y_0, Y_1, Y_2|\set{\vec{u}_k(i)|\forall k\in\apSet}, \Policy(\Stat_i)}
            \nonumber\\
            =& \prod_{k\in\apSet} \Pr\Brace{N^{(k)}_1,N^{(k)}_2}
                \Bracket{
                    \prod_{n=1}^{n^{(k)}_0 + N^{(k)}_1} p^{(\theta, i-1)}_{k,m}(j_n)
                }
                \Bracket{
                    \prod_{n=1}^{N^{(k)}_2} p^{(\theta, i)}_{k,m}(j_n)
                }
        \end{align*}
        where $N^{(k)}_1$ and $N^{(k)}_2$ are independent and follow two different Binomial distributions respectively as:
        \begin{align*}
            N^{(k)}_1 &\sim Bin\Paren{t^{(d)}_k, p^{(\lambda, i-1)}_{k,m}}
            \\
            N^{(k)}_2 &\sim Bin\Paren{t_B-t^{(d)}_k-t^{(u)}_{k,m}, p^{(\lambda, i)}_{k,m}}
        \end{align*}
    \end{section}
    
    %============================== REFERENCE =============================%
    \bibliographystyle{IEEEtran}
    \bibliography{main.bib,journal-ref.bib}
\end{document}