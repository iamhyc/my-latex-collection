\documentclass[10pt, conference, letterpaper]{IEEEtran}
\usepackage{cite}
\usepackage{xcolor,soul,framed}
\usepackage{amsmath,amsthm,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{color, soul}
\usepackage{algorithm, algorithmic}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{mathtools}
\graphicspath{ {./images/} }

%---------------------------------------------------------------%
\newtheorem{definition}{Denifition}
\newtheorem{assumption}{Assumption}
\newtheorem{problem}{Problem}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}
\newtheorem{example}{Example}
\newcommand{\eq}{=}
\newcommand{\domZ}{\mathbb{Z}_{*}}
\newcommand{\vecOne}{\mathbf{1}}
\newcommand{\ind}{\mathbf{I}}
\newcommand{\mat}{\mathbf}
\newcommand{\define}{\triangleq}
\renewcommand{\vec}{\mathbf}
\DeclarePairedDelimiter\set\{\}
% \DeclarePairedDelimiter\set\bigg(\bigg)
%---------------------------------------------------------------%
\newcommand{\apSet}{\mathcal{K}}
\newcommand{\esSet}{\mathcal{M}}
\newcommand{\jSet}{\mathcal{J}}
\newcommand{\wSet}{\mathcal{W}}
\newcommand{\uSet}{\mathcal{U}}
\newcommand{\cSet}{\mathcal{C}}
\newcommand{\Stat}{\mathbf{S}}
\newcommand{\Obsv}{\mathcal{O}}
\newcommand{\Policy}{\mathbf{\Omega}}
%---------------------------------------------------------------%

\begin{document}

    %=============================== TITLE ===============================%
    \title{
        Meet-in-Future: Distributed Online Job Dispatching with Obsolete Information in Edge Computing System
    }
    \author{
        \IEEEauthorblockN{Yuncong Hong$^{*\dagger}$}
        \IEEEauthorblockA{
            $*$Southern University of Science and Technology, P.R. China,
            $\dagger$The University of Hong Kong, Hong Kong,\\
            $\ddagger$University of Science and Technology of China, P.R. China
        }
    }
    \maketitle

    %============================== ABSTRACT ==============================%
    \begin{abstract}
        \label{sec:abstract}
        Edge computing is believed to be the solid solution for time-sensitive big data real-time calculation. The cooperation among edge servers in the same coalition usually causes ineffective task scheduling due to obsolete information sharing, which is hard to tackle even with extra centralized agent design. In this work, we formulate the problem with job dispatching in distributed Edge Computing system, and identify the difficulty exists in cooperation between APs (Access Points) and ESs (Edge Servers) with delayed information. We design the broadcast information in the system and formulate the corresponding problem into a MDP problem. The value function approximation and \st{one-step policy iteration method is adopted to obtain a sub-optimal dispatching policy whose performance can be bounded analytically}.
    \end{abstract}

    % \begin{IEEEkeywords}
    %     Edge Computing, Job Dispatch, Delayed Information, Collective Observability, Distributed Multi-agent MDP
    % \end{IEEEkeywords}

    %============================ INTRODUCTION ============================%
    \begin{section}{INTRODUCTION}
        \label{sec:introduction}
        Our claims:
        \begin{itemize}
            \item Related works on scheduling in edge computing, mostly with centralized agent to apply action and seldomly take delayed information impact into consideration;
            \item Edge Server, Access Point, User Equipment; layered structure where decision is made distributedly on APs and computation is carried out on ESs; The AP-ES fully connected structure is reasonable, for example C-RAN to separate communication and computation 
            \item We identify the delayed system information is un-acceptable for explosion \emph{delay-sensitive jobs} in edge computing, and it's hard to establish cooperation among APs because of obsolete information;
            \item information sharing for cooperation is designed via (aligned) broadcast, job dispatch decision should be made immediately based on the previous collective information;
        \end{itemize}

        Our contributions:
        \begin{itemize}
            \item identify a instant job dispatch fully-distributed cooperative way, and avoid the centralized agent design;
            \item identify the uploading process may affect the heuristic greedy algorithm performance; identify the delay-information affected decision making;
            \item propose a global consensus state method to formulate the MDP problem (we use MDP definition in \cite{sutton1998introduction});
            \item adopt value function approximation to reduce the traditional algorithm complexity, and come up with distributed online learning algorithm;
        \end{itemize}

        Related works:
        \begin{itemize}
            \item The earliest related works we find is \cite{ref-01} (cited 167 times). In this work, the single agent is assumed not able to observe the global state, and thus they need communication to establish cooperation by sharing \emph{information}. The agent considers communication as extra action to synchronize the states and thus incurs extra cost. \\
            However, the communication is without delay, and converted into POMDP problem.
            \item The other work \cite{ref-02} considers continuous state observation with constant or stochastic delay with single agent. \\
            However, 
        \end{itemize}

    \end{section}

    %============================ SYSTEM MODEL ============================%
    \begin{section}{SYSTEM MODEL}
        \label{sec:model}
        \begin{subsection}{Network Model}
            The network topology of the MEC system considered is illustrated in Fig. \ref{fig:system}, which is composed of three elements. The user equipment (UE) is connected to access point (AP). The AP provides network access to all the UEs connected and also fully connected with each other to share local information. The AP itself is assumed with no computation capability, and then dispatches the jobs from UEs to backend edge servers (ES) in a distributed cooperative way. Moreover, the network topology between AP cluster and ES cluster is also assumed fully connected for the reason that they are in the same coalition.
            \begin{figure}[ht]
                \centering
                \includegraphics[width=0.45\textwidth, trim={0.5cm 0.5cm 0.5cm 0.5cm}, clip]{system-model.pdf}
                \caption{The Illustration of MEC System Model}
                \label{fig:system}
            \end{figure}

            Let $\mathcal{K} \triangleq \set{1,\dots,K}$ and $\mathcal{M} \triangleq \set{1,\dots,M}$ denote the set of APs and set of ESs in the MEC system respectively. We adopt \emph{timeslot} lasting for $\kappa$ seconds as the minimum time slice in the system, which is indexed with $t$. The dispatching and scheduling decision on AP and ES side respectively are all applied based on this timing. Furthermore, we assume the job arrival process for AP nodes is illustrated as follow:
            \begin{assumption}
                (Job Arrival Process at AP).
                We assume that the job arrival process $A_k(t)$ for $k$-th AP is i.i.d over the $t$-th timeslot and each with Bernoulli distribution as $A_k(t) \sim Bernoulli(\lambda_k)$.  According to Poisson Limit Theorem, we identify the arrival process as memory-less exponential process and with average arrival rate as $\mathbb{E}[A_k(t)] = \lambda_k$.
                This assumption implies that there will be at most one job arrives AP in one timeslot from all the UEs connected.
            \end{assumption}

            There are two main communication process with APs and ESs engaged based on the network topology elaborated above. We assume the communication latency is rather deterministic between two nodes and assign the delay time directly w.r.t transmission content for convenience.

            The first one is \emph{uploading process} where AP dispatches jobs to corresponding ESs. The uploading time is {\color{red}job-independent} and deterministic for all kinds of jobs on AP-ES link, which is denoted as $T^{prop}_{k,m}$ for from $k$-th AP to $m$-th ES, and the uploading time always lasts for integer timeslots. \emph{Parallel uploading} is enabled on AP to alleviate the cost caused by serially uploading process. As the arrival process and uploading time is bounded, there will be at most $\lambda_k \cdot \max_m(T^{prop}_{k,m})$ jobs in transmission on $k$-th AP which results into finite bandwidth requirement.
            
            The other one is \emph{broadcast process} to facilitate cooperative dispatching decision.
            The information sharing among distributed AP nodes is designed via broadcast to achieve global optimality. The AP nodes should broadcast their system information to the other AP nodes, and the ES nodes should broadcast their information to all the AP nodes. More specifically, all the APs and ESs start to broadcast at the same start point at the beginning of one time slot and repeat broadcasting with the same interval as $T_B$ timeslots, which is called \emph{aligned broadcast}.
            Let $d^{(AP)}_{k,k'}$ denotes the broadcast delay from $k'$-th AP $\forall k'\in\apSet$ to $k$-th AP w.r.t. the last broadcast interval where $d^{(AP)}_{k,k} \equiv 0$ for convenience; and let $d^{(ES)}_{k,m}$ denotes the broadcast delay from $m$-th ES $\forall m\in\esSet$. We assume that the broadcast interval is always larger than the broadcast delay, i.e. $T_B > d_{k,i}$, and we elaborate the concept called \emph{consensus delay} for AP nodes receiving the all broadcast information as:
            \begin{definition}
                (Consensus Delay).
                \begin{align}
                    \hat{d}_k = \max(\set{d^{(AP)}_{k,j}|\forall k\in\apSet}, \set{d^{(ES)}_{k,m}|\forall m\in\esSet}),
                \end{align}
                where $d^{(AP)}_{k,k} \equiv 0$. The consensus delay for $k$-th AP is the delay after the last broadcast point where it could update the global information consensus.
            \end{definition}
            The precision of aligned broadcast could be guaranteed by timely synchronization protocol or with GPS device, which is not the main focus in our discussion.
        \end{subsection}

        \begin{subsection}{Computation Model}
            For computation process on edge servers, we adopt \emph{unrelated machines} assumption in \cite{tan-online}, where the job processing time on different servers are machine dependent and variant of resource or VM (virtual machine) constraints. The processing time is with upper bound as $L_C$, and the job set is denoted as $\mathcal{J}$ {\color{red}where $J=(L_C)^M-1$ for all possible length combination; the $j$-th job in $\jSet$ has the computation time as $\vec{l}_j = ([l_j^{(1)}, l_j^{(2)}, \dots, l_j^{(M)}] + \vecOne^M)$ on edge servers cluster $\esSet$, where $\vec{l}_j$ is the index $j$ under $L_C$-base denotation.} Additionally, we denote PDF of the release distribution over $\jSet$ as $p_j \define \Pr(j\in\jSet)$.
            We assume the scheduling policy on all the servers  as following:
            \begin{assumption}
                (Scheduling Policy).
                All the edge servers adopt \emph{FCFS} (First-Come-First-Serve) as job scheduling policy, i.e. the job earlier arrives at the server would get served earlier. And we note that the arrival order is not only determined by job arrives at the access point, but also related with the uploading latency.
            \end{assumption}
        \end{subsection}

        \begin{subsection}{Job Dispatching Model}
            The job dispatching process is composed of three stages: waiting on APs for uploading, in uploading to servers, and waiting for service in servers queue. The three stages results into jobs set accumulation on APs and ESs which is illustrated and the Markovian transition relationship between the adjacent timeslot in Fig. \ref{fig:trans}.

            The local states on APs and ESs are divided into three job set:
            \begin{itemize}
                \item Let $\wSet_{k}(t)$ denotes the job set on $k$-th AP $\forall k \in \apSet$, which comprises the jobs waiting for dispatching decision at $t$-th timeslot; $w \in \wSet_{k}(t)$ and $w \triangleq (\vec{l}_w)$, where $w$ denotes the tuple containing one element $\vec{l}_w \in \domZ^M$ as the computing length on all $M$ unrelated edge servers.
                \item Let $\uSet_{k,m}(t)$ denotes the jobs in uploading from $k$-th AP to $m$-th ES in $t$-th timeslot $\forall k \in \apSet, m \in \esSet$; $u \triangleq (l_u, T_{u}(t)) \in \uSet_{k,m}(t)$, $l_u$ denotes the computing length on $m$-th server and $T_{u}(t)$ records the remaining time for uploading completed.
                \item Let $\cSet_{m}(t)$ denotes the jobs waiting for computing on $m$-th ES in $t$-th timeslot; $c \triangleq (t_c, T_{c}(t)) \in \cSet_{m}(t)$; $t_c$ denotes for arriving timestamp at server, $T_{c}(t)$ denotes for the remaining time for computing completed.
            \end{itemize}

            Then we have the denotation of system observation in $t$-th timeslots on left-hand side in the figure as:
            \begin{align}
                \mathcal{O}(t) \triangleq (\bigcup\limits_{k\in\apSet}\wSet_{k}(t), \bigcup\limits_{k\in\apSet, m\in\esSet}\uSet_{k,m}(t), \bigcup\limits_{m\in\esSet}\cSet_{m}(t))
            \end{align}
            and as the transition is initialized by \emph{dispatching decision} and therefore automatically been uploaded and computed, we give the definition for decision action here:
            \begin{definition}
                (Dispatching Action).
                The dispatching action space is applied job-wise in the waiting job set denoted as $a: \jSet \times \set{0,1,\dots,M}$, where $(j, 0)$ means $j$-th job should keep waiting and $(j,m\neq0)$ means $j$-th job should be uploaded to $m$-th ES. As the jobs should always been uploaded to server at last, the probability of infinite waiting decision applied on the same job should be almost zero.
            \end{definition}

            Then we characterize the job dispatching process by Markovian transition between adjacent timeslots.
            Then we establish the relationship between those indicator functions with $\mathcal{O}(t+1)$ over the three different components as:

            and we notice that no matter job arrival or decision on $\wSet$ happened or not, the attributes of jobs in $\uSet$ and $\cSet$ have to change according to the deterministic rule about uploading and scheduling respectively.

            Additionally, the broadcast design is not engaged in dispatching model for now but it will have affects on dispatching decision which will be illustrated in next section.
        \end{subsection}
    \end{section}

    %============================ FORMULATION =============================%
    \begin{section}{FORMULATION}
        \label{sec:formulation}
        In this section, we formulate the standard MDP problem based on the MEC system elaborated above. The optimization problem will be formulated globally on dispatching decisions on APs, but applied fully distributed on each AP with broadcast design to share information.

        \begin{subsection}{System State and Scheduling Policy}
            Before we give the canonical definition for system states in the distributed system, we firstly clarify the broadcast information from AP nodes and ES nodes. For convenience, we denote the broadcast point as $T_\tau$ where:
            \begin{align}
                T_\tau = \tau \cdot T_B, \tau=0,1,2\dots
            \end{align}
            The observation at $\tau$-th broadcast, $\Obsv(T_\tau)$ is denoted as $\Obsv_\tau$ for short. The broadcast information is based on $\Obsv_\tau$ as:
            \begin{definition}(Broadcast Information).
                The $k$-th AP would broadcast all the job set information at $T_\tau$ as $\wSet_{k}(T_\tau), \bigcup\limits_{m\in\esSet}\uSet_{k,m}(T_\tau)$.
                Thus the composed broadcast information at $T_\tau$ is:
                \begin{itemize}
                    \item System observation at $T_\tau$ timeslot, $\Obsv_\tau$;
                \end{itemize}
            \end{definition}

            This broadcast information is also called \emph{global consensus} in Fig. \ref{fig:br-trans} \hl{(need to modify the state denotation in figure)} that $k$-th AP would only obtain the broadcast information completely after the \emph{consensus delay} $\hat{d}_{k}$ w.r.t to the last broadcast point. The system state of the formulated MDP problem is on the global consensus but locally computed at each AP nodes, given as following:
            \begin{definition}(System State).
                At the $\tau$-th broadcast on broadcast point $T_\tau$, the global state for all AP nodes is denoted as: $\Stat_\tau = (\Obsv_{\tau}, \Obsv_{\tau-1}, \vec{n}_\tau), (\tau=1,2,\dots)$.
                More specifically, the $k$-th AP nodes would come up with this global state consensus only after $\hat{d}_k$ timeslots, and it adopt policy based on the obsolete information.
            \end{definition}
            \begin{figure}[ht]
                \centering
                \includegraphics[width=0.45\textwidth]{broadcast-trans.png}
                \caption{Global Consensus and Transition with Delayed Action}
                \label{fig:br-trans}
            \end{figure}

            The dispatching policy $\vec{\Omega}(\Stat_\tau)$ is actually composed of all AP nodes based on obsolete information $\Obsv_{\tau-1}$ and the updated information $\Obsv_{\tau}$ after the consensus delay $\hat{d}_k$ respectively. The composed policy over job-wise action space $\vec{a}$ is defined as following:
            \begin{definition}(Compounded Dispatching Policy).
                The compounded dispatching policy over $\Stat\tau$ is defined as $\Policy(\Stat_\tau)$ which is composed of the local policy $\Omega_k(\Stat_\tau), \forall k\in\apSet$ as:
                \begin{align}
                    \vec{\Omega}(\Stat_\tau) \triangleq [\Omega_1(\Stat_\tau), \dots, \Omega_K(\Stat_\tau)]
                \end{align}
                More specifically, $\Omega_k(\Stat_\tau)$ is composed of two-stage policy with $\tilde{\Omega}_k(\Obsv_{\tau-1})$ and $\tilde{\Omega}_k(\Obsv_{\tau})$ as:
                \begin{align}
                    \Omega_k(\Stat_\tau) = 
                    \begin{cases}
                        {\omega}_k(\Obsv_{\tau-1}), & 0 \leq \Delta{t} < \hat{d}_k
                        \\
                        {\omega}_k(\Obsv_{\tau}), & \hat{d}_k \leq \Delta{t} \leq T_B
                    \end{cases}
                \end{align}
                where $t\in[T_{\tau-1}, T_{\tau}] ,\Delta{t} \define t - T_{\tau-1}$; ${\omega}_k(\Obsv_\tau)$ denotes the dispatching policy, which is a mapping from $\Obsv_\tau$ to a probabilistic distribution over action space $\vec{a}$ for $k$-th node.
            \end{definition}

            As the state transition from $\Stat_{\tau}$ to $\Stat_{\tau+1}$ is driven by the compounded policy with the obsolete state $\Obsv_{\tau-1}$, and the updated state $\Obsv_{\tau}$ with delay.
        \end{subsection}

        \begin{subsection}{The Optimization Problem}
            The optimization target of our problem is to minimize the \emph{average response time} of all jobs, which is composed of waiting time on AP, uploading time, waiting time on ES and service time on ES. According to \emph{Little's Law}, the average time over all the jobs is equally as number in system accumulation in each timeslot. The cost function is:
            \begin{align}
                g\bigg(\Stat_\tau, \Policy(\Stat_{\tau-1})\bigg) \define \sum_{k\in\apSet}\sum_{m\in\esSet} u_{k,m}(\tau) + \sum_{m\in\esSet}|Q_m(\tau)| 
            \end{align}
            which is actually deterministic with the $\tau$-th broadcast information.
            Our distributed optimization problem definition is given as following:
            \begin{problem}
                (Distributed Cooperative Job Dispatching Problem).
                \begin{gather}
                    \min_{\Policy} \lim_{T \to \infty}
                        \mathbb{E}_{\Policy, \{A_k(t)|\forall k\in\apSet\}}
                            [\sum_{\tau=1}^{T} \gamma^{\tau-1} g(\Stat_\tau, \Policy(\Stat_{\tau-1}))|\Stat_1]
                \end{gather}
            \end{problem}

            According to \cite{sutton1998introduction}, the above problem could be solved by the following \emph{Bellman's equation}:
            \begin{align}
                V(\Stat_{\tau}) =& g(\Stat_\tau) +\gamma \min_{\Policy(\Stat_\tau)} \sum_{\Stat_{\tau+1}} \Pr\{\Stat_{\tau+1}|\Stat_{\tau}, \Policy(\Stat_\tau)\} V(\Stat_{\tau+1})
                \nonumber\\
                =& g(\Stat_\tau) +\gamma \min_{\Policy(\Stat_\tau)} \sum_{\Stat_{\tau+1}} \Pr\{\Stat_{\tau+1}|\Stat_{\tau}, \Policy(\Stat_\tau)\}
                \nonumber\\
               & \cdot [\sum_{k\in\apSet} {W}^{(k)}(\tilde{S}^{(k)}_{\tau+1}) + \sum_{m\in\esSet} {W}^{(m)}(\tilde{S}^{(m)}_{\tau+1})],
            \end{align}
            where $W^{(k)}=\mathbb{E}\{\}, \forall k\in\apSet$, and $W^{(m)}=\mathbb{E}\{\}, \forall m\in\esSet$

            There are totally $(K+1)$ transition matrix in $[T_{\tau}, T_{\tau+1})$ w.r.t. $\hat{d}_k$ and denoted as $\mat{P}^{\Delta{t}_k}$ in $\Delta{t}_k$ interval for all $k\in[0,1,\dots,K]$.
        \end{subsection}
    \end{section}

    %============================= ALGORITHM ==============================%
    \begin{section}{LOW-COMPLEXITY SOLUTION}
        \label{sec:algorithm}
        As the formulated problem above is of infinite states and the action space would be exponentially expanded with respect to number APs and ESs, we could not use traditional \emph{policy iteration} or \emph{value iteration} algorithm \cite{sutton1998introduction} for unacceptable computational complexity. To alleviate curse of dimensionality, we take one baseline policy to approximate the value function as $\tilde{V}(T_t)$ and carry out one-step iteration to come up with a better value function approximation.
        \hl{Traditional value iteration is intractable due to the following reasons: (1) the number of active devices is not fixed and the state space grows exponentially with the increasing number of active devices; (2) the spaces of small-scale fading and path-loss are continuous.}

        \begin{subsection}{Baseline Policy}
            \begin{problem}
                (Fixed FCFS Optimization).
                \begin{itemize}
                    \item no waiting stage;
                    \item locally greedy uploading;
                    \item FCFS scheduling (?);
                \end{itemize}
            \end{problem}

            \begin{definition}
                (Job Arrival Process at $n$-th ES).
            \end{definition}

            At last, we collect the cost according to the definition in our MDP problem but with respect to our approximate algorithm.
            \begin{align}
                & \tilde{V}^{\pi}(T_t)
                \nonumber%\\
                = E_{\pi} \{ \tilde{C}_{t} + \gamma \tilde{C}_{t+1} + \gamma^2 \tilde{C}_{t+2} + \dots |S_{t-1}=s \}
                % \nonumber\\
                % = & \sum_{k=0}^{\infty} \gamma^{k} \sum_{t'=kT^{br}+1}^{(k+1)T^{br}} \sum_{s'} \tilde{P}^{t'}_{s,s'} \times |s'|
            \end{align}
            % where $\tilde{P}_{s,s'}$ is fixed under the given policy $\vec{\beta}_{\pi}$.
        \end{subsection}

        \begin{subsection}{The Distributed Algorithm}
            Then we introduce the one-step iteration algorithm in this section:
            % [\IF, \ENDIF], [\FOR, \TO, \ENDFOR], [\WHILE, \ENDWHILE], \STATE, \AND, \TRUE
            \begin{algorithm}[H]
                \caption{Distributed Algorithm for $k$-th AP}
                \begin{algorithmic}
                    \WHILE{\TRUE}
                        \STATE (in progress...)
                        % \FOR{$k \in \mathcal{K}$}
                        %     \STATE fix policy $\vec{\Omega}^{(k)}(t) \forall k' \neq k$
                        % \ENDFOR
                    \ENDWHILE
                \end{algorithmic}
            \end{algorithm}
        \end{subsection}
        
    \end{section}

    %============================ EVALUATION ==============================%
    \begin{section}{EVALUATION}
        \label{sec:evaluation}
        (in progress)
    \end{section}

    %============================= CONCLUSION =============================%
    \begin{section}{CONCLUTION}
        \label{sec:conclusion}
        The future work to mention:
        \begin{itemize}
            \item non-aligned broadcast
            \item broadcast failure
            \item randomized broadcast delay
        \end{itemize}
    \end{section}

    %============================== REFERENCE =============================%
    \bibliographystyle{IEEEtran}
    \bibliography{main.bib}
\end{document}