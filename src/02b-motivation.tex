\section{Motivation}
%----------------------------------------------------------------------------------------%
Nowadays, the edge computing system always presences in a distributed formation.
There are clusters of Edge Servers in cooperation but separated physically, together serve the jobs released from edge devices.
Different from classical Cloud Server scenario usually with centralized scheduler design, the cooperation among clusters encounters with problems which disturb it from centralization design, such as: reasonable cooperation mechanism, un-timely and disorder information sharing and unpredictable underlaid network condition (compared with data center network).

%NOTE: 
Firstly, an efficient information sharing scheme design is needed in such distributed system.
In edge computing scenario, we consider the clusters are of same coalition and they cooperate to achieve a global optimal target, e.g. minimum job execution time.
The local greedy policy under this situation would have no insight.
We design a periodic sampling scheme in our problem.
\begin{example}[Periodic Sampling Error]
    The periodic sampled status is already a good estimation for Job Completion Time (JCT).
\end{example}
Under the assumption of periodic information sharing, it's actually a quite practical model 

%NOTE: second point
Secondly, with intensive jobs release from edge devices, the \brdelay is the key issue to take care in dispatching decision design.
\begin{example}
    Fixed one AP, the one would adopt sub-optimal policy before receiving the information. A.k.a, sub optimal plus optimal in that period is not optimal
\end{example}
The insight exists in: the bottleneck may exist in Barrel Theory that one lacking AP could ruin the whole cooperation on the target.
And we only do delay-aware instead of delay-adapt policy.

%NOTE: third point
Last but not least, the biggest challenge in the way of distributed decision making is unpredictability of underlaid network delay.
In this article, we propose model-based reinforcement learning problem formulation, to adapt with stochastic environment.
To alleviate the curse of dimensionality, we propose a one-step value iteration approximation to solve the Bellman's Equation, which is with performance guarantee.

%NOTE: additional point
Additionally, we don't consider further offloading onto cloud infrastructure in our scheme.
For two reasons: maybe it's without performance guarantee as there's no explicit computation model for cloud; maybe edge clusters cooperation is already enough as a replacement; 
