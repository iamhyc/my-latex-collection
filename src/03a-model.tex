\section{System Model}
%----------------------------------------------------------------------------------------%
\subsection{Network Model}
We consider an edge computing system with $K$ Access Points (APs) and $M$ edge servers, which are connected in a network as illustrated in Fig.\ref{fig:system}.
The sets of APs and edge servers are denoted as $\apSet \define \set{1,\dots,K}$ and $\esSet \define \set{1,\dots,M}$, respectively.
Each AP collects the computation jobs from the mobile users within its coverage, and makes decision on the processing edge servers from the set $\esSet$.
\delete{v5}{
Each AP collects the computation jobs from the mobile users within its coverage, and makes decision for each job on which edge server it should be dispatched to.
}
In this paper, we shall focus on the decentralized dispatcher design at each AP.
\accept{
    Specifically, each AP and edge server periodically broadcast their state information (e.g., computing queue length, list of jobs being uploaded from APs to edge servers and etc.).
    One AP updates its strategy on job dispatching when receiving the broadcast state information.
    Due to random transmission latency in the network, it is not sure when one AP can receive the complete broadcast information, and the dispatching design could take this practical issue into consideration.
}

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.80\textwidth]{system-model.pdf}
    \caption{The Illustration of MEC System Model}
    \label{fig:system}
\end{figure}

%NOTE: [job space support and arrival process]
Without loss of generality, it is assumed that there are $J$ types of computation jobs supported in this system, which are denoted via the set $\jSpace \define \set{1,\dots,J}$.
The time axis of each AP is organized by time slots.
The job arrivals in each time slot are modelled via independent Bernoulli distributions.
Specifically, the arrivals of the $j$-th job type at the $k$-th AP in different time slots are independent and identically distributed (i.i.d.) Bernoulli random variables, and the arrival probability is denoted as $\lambda_{k,j}$ ($\forall k\in\apSet, j\in\jSpace$).

%NOTE: [uploading process]
Each AP then immediately dispatches each type of received jobs to one edge server.
Let $\omega_{k,j}$ denotes the index of edge server for the processing of the $j$-th types of jobs dispatched from the $k$-th AP ($\forall k\in\apSet, j\in\jSpace$).
Different types of jobs may have different distributions on the input data size.
Moreover, due to the random traffic in the network, the job uploading from one AP to one edge server consumes a random number of time slots.
It's assumed that the distributions of uploading delays are independent between any two uploading jobs.
Hence, we denote $\mathcal{U}_{k,m,j}$ as the uploading delay distribution ranged in $(0, \Xi]$ (with the unit of time slot) for the $j$-th type of jobs from the $k$-th AP to the $m$-th edge server with support ($\forall k\in\apSet, m\in\esSet, j\in\jSpace$).
In practice, the distribution of uploading delay may not be known to the APs or edge servers in advance.
\delete{v4}{
    It's assumed that the distributions of uploading delays are independent between any two uploading jobs.
    Denote the uploading delays are i.i.d for the $j$-th type of jobs from the $k$-th AP to the $m$-th edge server, which is denoted as $\mathcal{U}_{k,m,j}$ ranged in $(0,\Xi]$ with the unit of time slot ($\forall k\in\apSet, m\in\esSet, j\in\jSpace$).
}

%NOTE: [processing process]
There are $J$ virtual machines (VMs) on each edge server for the computation of $J$ job types, respectively.
Different edge servers have different processing capability on different job types.
For each type, the uploaded jobs are computed in a First-Come-First-Serve (FCFS) manner.
Hence, a processing queue with maximum $L_{max}$ jobs is established for each VM.
The arrival jobs will be discarded when the processing queue is full.
Furthermore, we adopt the \emph{unrelated machines} assumption in \cite{tan-online} for job processing on edge servers.
Specifically, it is assumed that different types of jobs on different edge servers have different distributions of computing time.
We denote $C_{m,j}$ as the computing time distribution (with the unit of time slot) of the $j$-th job type on the $m$-th edge server, and $f_{m,j}(x)$ as the probability mass function (PMF) of $C_{m,j}$ where $x$ is ranged in $(0, c_{m,j}]$ ($\forall m\in\esSet, j\in\jSpace$).

\delete{v5}{
    The job processing time on different servers are random and machine dependent, which implies that different types of jobs on different edge servers have different processing time distributions.
    We denote $\mathcal{C}_{m,j}$ as the processing time distribution of the $j$-th type job on the $m$-th edge serer, whose range is in $(0, c_{m,j}]$ with the unit of time slot ($\forall m\in\esSet, j\in\jSpace$).
}

%----------------------------------------------------------------------------------------%

\subsection{Periodic Broadcast of State Information}
%NOTE: Periodic Broadcast is Indispensable
In our system, each AP dispatches different types of computation jobs in a fully cooperative manner, where the jobs are dispatched to achieve a global optimality.
To facilitate such dispatching decision, each AP should collect the information from other APs and edge servers.
It's assumed that every APs and edge servers broadcast their information every $t_B$ time slots as illustrated in Fig.\ref{fig:brd-timeline}.
\delete{v4}{
    Furthermore, we denote $({i,n})$ as the $n$-th time slot in $i$-th broadcast interval, which is the interval between $(i-1)$-th and $i$-th broadcast ($i\in\domP$).
    Especially, we have $({i}) \define ({i,0})$ as the index of $i$-th broadcast time slot and call it $i$-th \brpoint~($i\in\domP$).
}
\begin{figure}[ht]
    \centering
    \includegraphics[width=0.80\textwidth]{brd-timeline.pdf}
    \caption{The Timeline Illustration of State Information Broadcast and Receiving}
    \label{fig:brd-timeline}
\end{figure}

%NOTE: State and Broadcast Information for AP
One AP shall maintain information about the number of jobs still in uploading. 
And due to the uploading time of one job is unknown until it's been uploaded, it further has counters to record the elapsed time slots for each job.
More specifically, at the $n$ time slot in the $t$-th interval, the number of the $j$-th type job been uploaded to the $m$-th edge server $\xi$ time slots ago from $k$-th AP is denoted as $R^{(k)}_{m,j,\xi}({t,n})$ ($\forall k\in\apSet, m\in\esSet, j\in\jSpace, \xi\in(0,\Xi]$).
The broadcast information of the $k$-th AP at the $t$-th broadcast ($t\in\domZ$) is defined as follows.
\begin{align}
    \mathcal{R}_{k}({t}) \define \set{R^{(k)}_{m,j,\xi}({t}) | \forall m\in\esSet, j\in\jSpace, \xi \in [0,\Xi]},
\end{align}
where we have $\vec{R}^{(k)}_{m,j} \define ( R^{(k)}_{m,j,0},\dots,R^{(k)}_{m,j,\Xi} )$ denote the vector of random variables for convenience.

%NOTE: State and Broadcast Information for ES
One edge server shall maintain information about the computing queue status for each VM.
More specifically, at the $n$ time slot in the $t$-th interval, the $m$-th edge server have $L_{m,j}({t,n})$ and $\eta_{m,j}({t,n})$ denote the pending number and the first job remaining time of the $j$-th type job, respectively ($\forall m\in\esSet, j\in\jSpace$).
The broadcast information of the $m$-th edge server at the $t$-th ($t\in\domZ$) broadcast is defined as follows.
\begin{align}
    \mathcal{Q}_{m}({t}) \define \set{Q_{m,j}({t}) | \forall j\in\jSpace},
\end{align}
where $Q_{m,j} \define (L_{m,j}, \eta_{m,j})$.
And the whole broadcast information from all APs and edge servers at the $i$-th broadcast ($i\in\domZ$) is denoted as:
\begin{align}
    \Obsv({t}) \define
        \Brace{
            \mathcal{R}_{k}({t}), \mathcal{Q}_{m}({t}) | \forall k\in\apSet, m\in\esSet
        }.
\end{align}

%NOTE: Receiving points definition, denotation and unpredictable
According to Fig.\ref{fig:brd-timeline}, different APs would receive different parts of broadcast information at different time slots.
For $t$-th broadcast ($t\in\domZ$), the $k$-th AP would receive the broadcast information from $k'$-th AP after some delay $D^{\dagger}_{k,k'}({t})$, and $D^{\ddagger}_{k,m}({t})$ for the information from the $m$-th edge server ($\forall k' \neq k \in\apSet, m\in\esSet$).
We call the delay after which one AP (saying the $k$-th AP, $\forall k\in\apSet$) could receive the whole broadcast information as \brdelay, which is defined as follows.
\begin{align}
    D_{k}({t}) \define \max\Paren{\Brace{
        D^{\dagger}_{k,k'}({t}),
        D^{\ddagger}_{k,m}({t}) | \forall k' \neq k \in \apSet, m\in\esSet
    }}.
\end{align}
Due to the randomness of the network traffic, the \brdelay~shall be random based on the uncertainty of the arrival delay of each partial broadcast information.
Thus APs have i.i.d. distributions of \brdelay, which is denoted as $D_{k}$ ($\forall k \in \apSet$).

As a high frequency broadcast design could result into \emph{broadcast storm} and block the normal network traffic, we introduce a slow enough broadcast interval selection in the system.
The broadcast interval is always larger than the maximum \brdelay, i.e. $t_B > \hat{D}_k$ ($\forall k\in\apSet$), where $\hat{D}_k$ is the upper bound for $D_{k}({t})$ ($t\in\domP$).
The broadcast interval selected implies that any AP would always receive the whole broadcast information once before the next broadcast, and the \brdelay~is comparable to the broadcast interval thus not negligible.

Each AP tries to update its dispatching decisions once it receives the latest system state via broadcast.
Denote the dispatching policy of the $k$-th AP ($\forall k\in\apSet$) based on the broadcast information $\Obsv({t})$ ($t \in\domP$) as follows.
\begin{align}
    &\tilde{\Omega}_{k}\Paren{\Obsv({t})} \define \set{\omega_{k,j}|\forall m\in\esSet, j\in\jSpace}
    ~(\forall k\in\apSet).
    \label{def_action}
\end{align}
The $k$-th AP would always adopt two phases polices in the $i$-th interval, i.e. $\tilde{\Omega}_{k}(\Obsv({t-1}))$ before receiving $\Obsv({t})$ and $\tilde{\Omega}_{k}(\Obsv({t}))$ afterwards.
The two phases policy of all APs together determine the information of $\Obsv({t+1})$ in the next interval.

However, the randomness of \brdelay~implies that one AP could not know other APs' \brdelay~in the same interval.
Thus, APs are unable to evaluate the impact introduced by others' policy on the next broadcast information and fail to establish exact cooperation.
An naive way to solve this problem is to force all APs update their policy only at the end of the interval, which introduces a inevitable lagging for a whole broadcast interval.
\delete{v4}{A toy example is given as follow.}

In the following problem formulation section, we will show that we could come up with better dispatching decision update solution which is aware of the \brdelay, and improve APs' dispatching decisions in an iterative way.
\fixit{
    Furthermore, with the help of algorithm design we could prove that our improved policy is with analytical performance bound under MDP framework.
}
%----------------------------------------------------------------------------------------%