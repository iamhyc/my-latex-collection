\begin{abstract}
    In this paper, we consider the distributive job dispatching problem in an edge computing network residing in Metropolitan Area Network (MAN), where the job arrivals, uploading latency and computation time are all random.
    Specifically, multiple access points (APs) collect jobs from the mobile users, and upload each job to one edge server according to the job type.
    The job arrivals, uploading latency and computation time are all random.
    APs and edge servers periodically broadcast their local state information, and the APs update their job dispatching strategy according to partially observable broadcast information.

    We formulate the optimization of job dispatching strategy as a partially observable Markov decision process (POMDP), whose minimization objective is a discount measurement of job delivery and computation delay.
    The conventional solution for POMDP is impractical due to huge complexity.
    In this paper, we propose a novel low-complexity solution framework to address the issue of algorithm complexity.
    Specifically, we first derive the analytical expression of the approximate value function according to a baseline policy.
    Based on it, the optimization of job dispatching strategy can be decoupled via an alternative policy iteration algorithm, so that the policy iteration of each AP can be made according to the partially observable system state information.
\end{abstract}
