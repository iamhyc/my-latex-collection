%NOTE: transition matrix and vector for AP
\appendices
\section{ Proof of Lemma \ref{lemma:w_ap} }
\label{append_1}
At the $n$-th time slot of the $t$-th broadcast interval, let $\hat{\vecG{\Theta}}^{(k,\Policy)}_{m,j}(t,n)$ denote the probability of job existence under dispatching policy $\Policy$ where the explicit definition is given as follows.
\begin{align}
    \hat{\vecG{\Theta}}^{(k,\Policy)}_{m,j}(t,n) \define \Bracket{
        \hat{\theta}^{(k,\Policy)}_{m,j}(0,t,n),
        \dots,
        \hat{\theta}^{(k,\Policy)}_{m,j}(0,t,n)
    },
\end{align}
where
{\small
\begin{align}
    \hat{\theta}^{(k,\Policy)}_{m,j}(\xi,t,n) \define
    \begin{cases}
        \lambda_{k,j} I[\omega_{k,j}(t)=m], &\xi=0, n < \mathcal{D}_{k}(t)
        \\
        \lambda_{k,j} I[\omega_{k,j}(t+1)=m], &\xi=0, n \geq \mathcal{D}_{k}(t) 
        \\
        \Pr\{R^{(k)}_{m,j}(\xi,t,n)=1\}, & \text{otherwise}
    \end{cases}.
\end{align}
}
The dispatching policy $\Policy$ only affects the first entry of the probability vector, i.e. the arrival probability of one job in the time slot.
Hence, we denote the time-invariant transition matrix $\hat{\Gamma}^{(k)}_{m,j}$ for the state transition on AP between adjacent time slots which is defined as follows.
\begin{align}
    \hat{\Gamma}^{(k)}_{m,j} &\define
    \begin{bmatrix}
        1 & \bar{p}^{(k)}_{m,j,0} &                       &        &                           \\
        & 0                     & \bar{p}^{(k)}_{m,j,1} &        &                           \\
        &                       & \ddots                & \ddots &                           \\
        &                       &                       & \ddots & \bar{p}^{(k)}_{m,j,\Xi-1} \\
        &                       &                       &        & 0                         \\
    \end{bmatrix},
\end{align}
where $\bar{p}^{(k)}_{m,j,\xi}$ denotes the probability of job still stay at the $k$-th AP in the next time slot as $\bar{p}^{(k)}_{m,j,\xi} = 1 - p^{(k)}_{m,j,\xi}$, and
\begin{align}
    p^{(k)}_{m,j,\xi} &\define \Pr\{U^{(k)}_{m,j} < (\xi+1) | U^{(k)}_{m,j}>\xi\}
\end{align}
denotes the probability of job offloading to the $m$-th edge server.
% And we note that $\theta^{(k)}_{m,j,0}(t,n)$ is purely determined by the arrival process and dispatching policy of the $j$-th type of job on the $k$-th AP, i.e. $\theta^{(k)}_{m,j,0}(t,n) = \lambda_{k,j} I[\omega_{k,j}(t) = m]$.

Hence, let $\vecG{\Theta}^{(\Policy, k)}_{m,j}(t)$ and $\Gamma^{(k)}_{m,j}$ denotes the probability vector and transition matrix for the adjacent broadcast interval, respectively.
Based on the previous definition in the time slot, the explicit definition is given as follows.
\begin{align}
    \vecG{\Theta}^{(\Policy, k)}_{m,j}(t) &\define \hat{\vecG{\Theta}}^{(\Policy, k)}_{m,j}(t,0)
    \\
    \vecG{\Theta}^{(k)}_{m,j}(t+1) &= \hat{\vecG{\Theta}}^{(k)}_{m,j}(t, \mathcal{D}_{k}(t)) \times (\hat{\Gamma}^{(k)}_{m,j})^{N-\mathcal{D}_{k}(t)},
    \nonumber\\
    \hat{\vecG{\Theta}}^{(k)}_{m,j}(t, \mathcal{D}_{k}(t)) &= \vecG{\Theta}_{m,j}(t) \times (\hat{\Gamma}^{(k)}_{m,j})^{\mathcal{D}_{k}(t)}.
\end{align}
% is composed of two-phase policy separated by $D_k(t)$, which is expressed as follows.

Given that the cost raised on APs is approximated with baseline policy $\Baseline$, the AP (saying the $k$-th AP) would adopt the same dispatching actions as $\Baseline(\Stat(t))$ before and after $\mathcal{D}_{k}(t)$ time slots in the $t$-th broadcast interval.
Hence, we have
\begin{align}
    \vecG{\Theta}^{(k,\Baseline)}_{m,j}(t+1) = \vecG{\Theta}^{(k,\Baseline)}_{m,j}(t) \times (\hat{\Gamma}^{(k)}_{m,j})^{N}.
\end{align}

Then, we could express the cost raised on AP under baseline policy $\Baseline$ as follows.
\begin{align}
    &\tilde{W}^{\AP}_{k,m,j}\Paren{\Stat(t+1)} =
    \Inorm{
        \Bracket{
            \vecG{\Theta}^{(k, \Baseline)}_{m,j}(t+1)
        }'
        \Bracket{
            \mat{I} - \gamma \Gamma^{(k)}_{m,j}
        }^{-1}
    }.
    \label{w_ap}
\end{align}


%NOTE: transition matrix and vector for ES
\section{ Proof of Lemma \ref{lemma:w_es} }
\label{append_2}
The state transition on edge server is composed of both arrival processes of all the APs in the corresponding \emph{potential AP set}, and the departure processes of jobs computation.
We first denote the offloading matrix $\bar{\Gamma}^{(k)}_{m,j}$ for the type-$j$ job offloaded from the $k$-th AP to the $m$-th edge server, and the offloading probability vector $\vecG{\rho}^{(k,+)}_{m,j}({t,n})$ as follows, respectively ($\forall k\in\apSet, m\in\esSet_{k}, j\in\jSpace$).
\begin{align}
    \bar{\Gamma}^{(k)}_{m,j}(t,n) &\define
    \begin{bmatrix}
        0 & p^{(k)}_{m,j,0} &                 &        &                     \\
        & 0                 & p^{(k)}_{m,j,1} &        &                     \\
        &                   & \ddots          & \ddots &                     \\
        &                   &                 & \ddots & p^{(k)}_{m,j,\Xi-1} \\
        &                   &                 &        & 1                   \\
    \end{bmatrix},
    \\
    \vecG{\rho}^{(k,+)}_{m,j}({t,n}) &\define \hat{\vecG{\Theta}}^{(k, \Policy)}_{m,j}({t,n}) \times \bar{\Gamma}^{(k)}_{m,j}.
\end{align}
However, the computational complexity of combinations of all the offloading probability vectors for the $m$-th edge server from its \emph{potential AP set} is unacceptable.
To alleviate the complexity, we rewrite the combinatorial arrival process on edge server as an equivalent Bernoulli process with \emph{small probability approximation}, i.e. there would be at most one job arriving in one time slot, with the probability as the expected arrival rate of the original combinatorial distribution.
Hence, the probability distribution of $\sum_{k\in\apSet} \vecG{\rho}^{(k,+)}_{m,j}({t,n})$ could be approximated as a Bernoulli distribution with the expected arrival rate denoted as $\hat{\beta}_{m,j}({t,n})$ whose definition is given as follows.
\begin{align}
    \hat{\beta}_{m,j}({t,n}) &\define \sum_{k\in\apSet} \sum_{\xi=0,\dots,\Xi-1} \mathbb{E}[\vecG{\rho}^{(k,+)}_{m,j,\xi}({t,n})]
    \label{eqn_0}
\end{align}

%NOTE: transition matrix and vector for Edge Server
% The transition matrix for state transition is affected by the baseline policy and the system states of APs.
% However, we notice that under the fixed baseline policy, the arrival process on edge servers would be stationary after the maximum uploading time from the initial interval, and thus the transition matrix is invariant of system states of APs.
% Let $\mat{P}_{m,j}(\Baseline_{t})$ be the transition matrix under baseline policy $\Baseline_{t}$ which is invariant of system states of APs
Thus we could obtain the denotation of transition matrix and probability vector for edge servers.
Let $\vecG{\mu}_{m,j}(t,n)$ and $P_{m,j}$ denote the probability vector and transition matrix of $Q_{m,j}(t,n)$ at the $n$-th time slot in the $t$-th broadcast interval, respectively ($\forall m\in\esSet, j\in\jSpace$).
\begin{align}
    \vecG{\mu}_{m,j}(t,n) \define [\Pr\{Q_{m,j}(t,n)=0\}, \dots, \Pr\{Q_{m,j}(t,n)=L_{max}\}].
\end{align}

Let $\hat{\vecG{\nu}}_{m,j}(t)$ denote the probability vector at the first time slot of the $t$-th broadcast interval.
The time-variant transition matrix composed of multiple transition matrix $\mat{\hat{P}}_{m,j}(\beta({t,n}))$ in all the time slots in $i$-th interval as follows.
\begin{align}
    \hat{\vecG{\nu}}({t,n+1}) &= \hat{\vecG{\nu}}({t,n}) \times \mat{\hat{P}}_{m,j}\Paren{\beta_{m,j}({t,n})}
    % \label{eqn_3}
    \\
    \vecG{\nu}(t+1) &= \vecG{\nu}(t) \times \prod_{n=0,\dots,N-1} \mat{\hat{P}}_{m,j}\Paren{\beta_{m,j}({t,n})},
    \label{eqn_4}
\end{align}

The entries $q_{i,j}$ of the matrix $\mat{P}$ are elaborated as follows.
\begin{itemize}
    \item When $i=0,j=0$,
    \item When $i=0, j\neq0$,
    \item When $i\neq 0, j=0$,
    \item When $i\neq 0, j\neq 0$
\end{itemize}

Then, we could express the cost raised on edge server under baseline policy $\Baseline$ as follows.
{\small
\begin{align}
    &\tilde{W}^{\ES}_{m,j}\Paren{\Stat(t+1)}
    = \sum_{i=0,\dots,\frac{\Xi}{T}} \gamma^{i} \mathbb{E}^{\Baseline}[ Q_{m,j}({t+i+1}) ]
    \nonumber\\
    &~~~~~~~~~~~~+ \gamma^{\frac{\Xi}{T}} 
    \vecG{\nu}({t+\frac{\Xi}{T}+1})
    \Paren{
        \mat{I} - \gamma \mat{P}_{m,j}(\beta_{m,j}(t))
    }^{-1} \vec{g}',
    \label{w_es}
\end{align}   
}


%NOTE: transition matrix and vector for ES
\section{ Proof of Lemma \ref{lemma:perform} }
\label{append_3}


%----------------------------------------------------------------------------------------%
\delete{v19}{
    Firstly, we notice that the transition function in equation (\ref{eqn:sp_0}) could be rewritten in the following form.
    \begin{align}
        & \Pr\Brace{ \Stat(t+1)|\Stat(t), \Policy(\Stat(t)) }
        \nonumber\\
        =& \prod_{j\in\jSpace} \Brace{
            \prod_{k\in\apSet} \prod_{m\in\esSet}
            \Pr\big\{
                \vec{R}^{(k)}_{m,j}(t+1) | \vec{R}^{(k)}_{m,j}(t), \Policy(\Stat(t))
            \big\}
            \nonumber\\
            &\times \prod_{m\in\esSet} \Pr\big\{
                Q_{m,j}(t+1) | Q_{m,j}(t), \Policy(\Stat(t))
            \big\}
        },
    \end{align}
    where the two production parts denote state transition on APs and edge servers under policy $\Policy$, respectively.

    \begin{lemma}[Small Probability Approximation]
        The probability distribution of $\sum_{k\in\apSet} \vecG{\rho}^{(k,+)}_{m,j}({t,n})$ could be approximated with a Bernoulli arrival process who is with the expected arrival rate denoted as ${\beta}_{m,j}({t,n})$.
    \end{lemma}
    \begin{proof}
        We notice that the job arrival distribution ${\beta}_{m,j}(t)$ is given by $\mathcal{R}(t)$, and the departure rate in one slot is deterministic as $1/N$.
        Thus the expectation of ${\beta}$ would be always far more smaller than $1$ as composed of all $K$ AP nodes.
        We take approximation on ${\beta}$ as Bernoulli distribution in each time slot.
    \end{proof}
}
%----------------------------------------------------------------------------------------%