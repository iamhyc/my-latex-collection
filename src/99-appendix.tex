%NOTE: transition matrix and vector for AP
\appendices
\section{ Proof of Lemma \ref{lemma:w_ap} }
\label{append_1}
At the $n$-th time slot of the $t$-th broadcast interval, let $\hat{\vecG{\Theta}}^{(k,\Policy)}_{m,j}(t,n)$ denote the probability of job existence under dispatching policy $\Policy$ where the explicit definition is given as follows.
\begin{align}
    \hat{\vecG{\Theta}}^{(k,\Policy)}_{m,j}(t,n) \define \Bracket{
        \hat{\theta}^{(k,\Policy)}_{m,j}(0,t,n),
        \dots,
        \hat{\theta}^{(k,\Policy)}_{m,j}(0,t,n)
    },
\end{align}
where
{\small
\begin{align}
    \hat{\theta}^{(k,\Policy)}_{m,j}(\xi,t,n) \define
    \begin{cases}
        \lambda_{k,j} I[\omega_{k,j}(t)=m], &\xi=0, n < \mathcal{D}_{k}(t)
        \\
        \lambda_{k,j} I[\omega_{k,j}(t+1)=m], &\xi=0, n \geq \mathcal{D}_{k}(t) 
        \\
        \Pr\{R^{(k)}_{m,j}(\xi,t,n)=1\}, & \text{otherwise}
    \end{cases}.
\end{align}
}
The dispatching policy $\Policy$ only affects the first entry of the probability vector, i.e. the arrival probability of one job in the time slot.
Hence, we denote the time-invariant and policy-independent transition matrix $\hat{\Gamma}^{(k)}_{m,j}$ for the state transition on AP between adjacent time slots which is defined below
\begin{align}
    \hat{\Gamma}^{(k)}_{m,j} &\define
    \begin{bmatrix}
        1 & \bar{p}^{(k)}_{m,j,0} &                       &        &                           \\
        & 0                     & \bar{p}^{(k)}_{m,j,1} &        &                           \\
        &                       & \ddots                & \ddots &                           \\
        &                       &                       & \ddots & \bar{p}^{(k)}_{m,j,\Xi-1} \\
        &                       &                       &        & 0                         \\
    \end{bmatrix},
\end{align}
where $\bar{p}^{(k)}_{m,j,\xi}$ denotes the probability of job still stay at the $k$-th AP in the next time slot as $\bar{p}^{(k)}_{m,j,\xi} = 1 - p^{(k)}_{m,j,\xi}$, and
\begin{align}
    p^{(k)}_{m,j,\xi} &\define \Pr\{U^{(k)}_{m,j} < (\xi+1) | U^{(k)}_{m,j}>\xi\}
\end{align}
denotes the probability of job offloading to the $m$-th edge server.
% And we note that $\theta^{(k)}_{m,j,0}(t,n)$ is purely determined by the arrival process and dispatching policy of the $j$-th type of job on the $k$-th AP, i.e. $\theta^{(k)}_{m,j,0}(t,n) = \lambda_{k,j} I[\omega_{k,j}(t) = m]$.

Hence, let $\vecG{\Theta}^{(\Policy, k)}_{m,j}(t)$ and $\Gamma^{(k)}_{m,j}$ denotes the probability vector and transition matrix for the adjacent broadcast interval, respectively.
Based on the previous definition in the time slot, the explicit definitions is given as
\begin{align}
    \vecG{\Theta}^{(\Policy, k)}_{m,j}(t) &\define \hat{\vecG{\Theta}}^{(\Policy, k)}_{m,j}(t,0)
    \\
    \vecG{\Theta}^{(k)}_{m,j}(t+1) &= \hat{\vecG{\Theta}}^{(k)}_{m,j}(t, \mathcal{D}_{k}(t)) \times (\hat{\Gamma}^{(k)}_{m,j})^{N-\mathcal{D}_{k}(t)},
    \nonumber\\
    \hat{\vecG{\Theta}}^{(k)}_{m,j}(t, \mathcal{D}_{k}(t)) &= \vecG{\Theta}_{m,j}(t) \times (\hat{\Gamma}^{(k)}_{m,j})^{\mathcal{D}_{k}(t)}.
\end{align}
% is composed of two-phase policy separated by $D_k(t)$, which is expressed as follows.

Given that the cost raised on APs is approximated with baseline policy $\Baseline$, the AP (saying the $k$-th AP) would adopt the same dispatching actions as $\Baseline(\Stat(t))$ before and after $\mathcal{D}_{k}(t)$ time slots in the $t$-th broadcast interval.
Hence, we have
\begin{align}
    \vecG{\Theta}^{(k,\Baseline)}_{m,j}(t+1) = \vecG{\Theta}^{(k,\Baseline)}_{m,j}(t) \times (\hat{\Gamma}^{(k)}_{m,j})^{N}.
\end{align}

Then, we could express the cost raised on AP under baseline policy $\Baseline$ as follows.
\begin{align}
    &\tilde{W}^{\AP}_{k,m,j}\Paren{\Stat(t+1)} =
    \Inorm{
        \Bracket{
            \vecG{\Theta}^{(k, \Baseline)}_{m,j}(t+1)
        }'
        \Bracket{
            \mat{I} - \gamma \Gamma^{(k)}_{m,j}
        }^{-1}
    }.
    \label{w_ap}
\end{align}


%NOTE: transition matrix and vector for ES
\section{ Proof of Lemma \ref{lemma:w_es} }
\label{append_2}
The state transition on edge server is composed of both arrival processes of all the APs in the corresponding \emph{potential AP set}, and the departure processes of jobs computation.
We first denote the offloading matrix $\bar{\Gamma}^{(k)}_{m,j}$ for the type-$j$ job offloaded from the $k$-th AP to the $m$-th edge server and the offloading probability vector $\vecG{\rho}^{(k)}_{m,j}({t,n})$ as follows, respectively ($\forall k\in\apSet, m\in\esSet_{k}, j\in\jSpace$).
\begin{align}
    \bar{\Gamma}^{(k)}_{m,j}(t,n) &\define
    \begin{bmatrix}
        0 & p^{(k)}_{m,j,0} &                 &        &                     \\
        & 0                 & p^{(k)}_{m,j,1} &        &                     \\
        &                   & \ddots          & \ddots &                     \\
        &                   &                 & \ddots & p^{(k)}_{m,j,\Xi-1} \\
        &                   &                 &        & 1                   \\
    \end{bmatrix},
    \\
    \vecG{\rho}^{(k)}_{m,j}({t,n}) &\define \hat{\vecG{\Theta}}^{(k, \Policy)}_{m,j}({t,n}) \times \bar{\Gamma}^{(k)}_{m,j}.
\end{align}
However, the computational complexity of combinations of all the offloading probability vectors for the $m$-th edge server from its \emph{potential AP set} is unacceptable.
To alleviate the complexity, we rewrite the combinatorial arrival process on edge server as an equivalent Bernoulli process with \emph{small probability approximation}, i.e. there would be at most one job arriving in one time slot with the probability as the expected arrival rate of the original combinatorial distribution.
Specifically, the probability distribution of $\sum_{k\in\apSet} \vecG{\rho}^{(k)}_{m,j}({t,n})$ is approximated as a Bernoulli distribution with the expected arrival rate denoted as $\hat{\beta}_{m,j}({t,n})$ whose definition is given as follows.
\begin{align}
    \hat{\beta}_{m,j}({t,n}) &\define \sum_{k\in\apSet} \sum_{\xi=0,\dots,\Xi-1} \mathbb{E}[\vecG{\rho}^{(k)}_{m,j,\xi}({t,n})]
    \label{eqn_0}
\end{align}

%NOTE: transition matrix and vector for Edge Server
Let $\hat{\vecG{\nu}}_{m,j}(t,n)$ denote the probability vector of $Q_{m,j}(t,n)$ at the $n$-th time slot in the $t$-th broadcast interval ($\forall m\in\esSet, j\in\jSpace$)
{\small
\begin{align}
    \vecG{\nu}_{m,j}(t,n) \define \Bracket{
        \Pr\{Q_{m,j}(t,n)=0\}, \dots, \Pr\{Q_{m,j}(t,n)=L_{max}\}
    }.
\end{align}
}
The transition matrix $\hat{\mat{P}}_{m,j}(\hat{\beta}_{m,j}(t,n))$ for adjacent time slots is determined by $\hat{\beta}_{m,j}(t,n)$ under policy $\Policy$, whose entries are elaborated as follows.
\begin{itemize}
    \item When $i=0,j=0$,
    \item When $i=0, j\neq0$,
    \item When $i\neq 0, j=0$,
    \item When $i\neq 0, j\neq 0$,
\end{itemize}

Hence, let $\vecG{\nu}_{m,j}(t)$ and $\mat{P}^{\Policy}_{m,j}(t)$ denote the probability vector and transition matrix for adjacent broadcast intervals, respectively.
Based on the previous definitions in the time slot, the explicit definition is give as
\begin{align}
    \vecG{\nu}_{m,j}(t) &\define \hat{\vecG{\nu}}_{m,j}(t,0)
    \\
    \mat{P}^{\Policy}_{m,j}(t) &\define \prod_{n=0,\dots,N-1} \hat{\mat{P}}_{m,j}(\hat{\beta}_{m,j}(t,n)),
    \\
    \vecG{\nu}_{m,j}(t+1) &= \vecG{\nu}_{m,j}(t) \times \mat{P}^{\Policy}_{m,j}(t)
\end{align}

Given that the cost raised on edge servers is approximated with baseline policy $\Baseline$, the transition matrix for state transition is affected by the baseline policy and the system states of APs which could not be decoupled.
However, we notice that under the fixed baseline policy, the arrival process on edge servers would be stationary after the \emph{maximum uploading time} from the initial interval, and thus the transition matrix is invariant of system states of APs.

Let $\mat{P}^{\Baseline}_{m,j}(t)$ be the transition matrix for the stationary arrival process under baseline policy $\Baseline$, where $\hat{\beta}_{m,j}(t,n) = \beta_{m,j}$ and
\begin{align}
    \beta_{m,j} &\define \sum_{k\in\apSet} \tilde{\lambda}^{(k)}_{m,j} \times \Pr\{ \xi<U_{k,m,j}<\xi+1 \}
    \nonumber\\
    &= \sum_{k\in\apSet} \tilde{\lambda}^{(k)}_{m,j},
\end{align}
where $\tilde{\lambda}^{(k)}_{m,j} \define \lambda_{k,j}I[\omega_{k,j}(t)=m]$ and $U_{k,m,j}$ denotes the random variable of job uploading time.

Then, we could express the cost raised on edge server under baseline policy $\Baseline$ as follows.
{\small
\begin{align}
    &\tilde{W}^{\ES}_{m,j}\Paren{\Stat(t+1)}
    = \sum_{i=0,\dots,\frac{\Xi}{T}} \gamma^{i} \mathbb{E}^{\Baseline}[ Q_{m,j}({t+i+1}) ]
    \nonumber\\
    &~~~~~~~~~~~~+ \gamma^{\frac{\Xi}{T}} 
    \vecG{\nu}({t+\frac{\Xi}{T}+1})
    \Paren{
        \mat{I} - \gamma \mat{P}_{m,j}(\beta_{m,j}(t))
    }^{-1} \vec{g}',
    \label{w_es}
\end{align}   
}
where $\vec{g}$ is the cost vector.

%NOTE: transition matrix and vector for ES
\section{ Proof of Lemma \ref{lemma:perform} }
\label{append_3}


%----------------------------------------------------------------------------------------%
\delete{v19}{
    Firstly, we notice that the transition function in equation (\ref{eqn:sp_0}) could be rewritten in the following form.
    \begin{align}
        & \Pr\Brace{ \Stat(t+1)|\Stat(t), \Policy(\Stat(t)) }
        \nonumber\\
        =& \prod_{j\in\jSpace} \Brace{
            \prod_{k\in\apSet} \prod_{m\in\esSet}
            \Pr\big\{
                \vec{R}^{(k)}_{m,j}(t+1) | \vec{R}^{(k)}_{m,j}(t), \Policy(\Stat(t))
            \big\}
            \nonumber\\
            &\times \prod_{m\in\esSet} \Pr\big\{
                Q_{m,j}(t+1) | Q_{m,j}(t), \Policy(\Stat(t))
            \big\}
        },
    \end{align}
    where the two production parts denote state transition on APs and edge servers under policy $\Policy$, respectively.

    \begin{lemma}[Small Probability Approximation]
        The probability distribution of $\sum_{k\in\apSet} \vecG{\rho}^{(k,+)}_{m,j}({t,n})$ could be approximated with a Bernoulli arrival process who is with the expected arrival rate denoted as ${\beta}_{m,j}({t,n})$.
    \end{lemma}
    \begin{proof}
        We notice that the job arrival distribution ${\beta}_{m,j}(t)$ is given by $\mathcal{R}(t)$, and the departure rate in one slot is deterministic as $1/N$.
        Thus the expectation of ${\beta}$ would be always far more smaller than $1$ as composed of all $K$ AP nodes.
        We take approximation on ${\beta}$ as Bernoulli distribution in each time slot.
    \end{proof}
}
%----------------------------------------------------------------------------------------%