%NOTE: transition matrix and vector for AP
\appendices
\section{ Proof of Lemma \ref{lemma:w_ap} }
\label{append_1}
At the $n$-th time slot of the $t$-th broadcast interval, let $\hat{\vecG{\Theta}}^{(k,\Policy)}_{m,j}(t,n)$ denote the probability of job existence under dispatching policy $\Policy$ where the explicit definition is given as follows.
\begin{align}
    \hat{\vecG{\Theta}}^{(k,\Policy)}_{m,j}(t,n) \define \Bracket{
        \hat{\theta}^{(k,\Policy)}_{m,j}(0,t,n),
        \dots,
        \hat{\theta}^{(k,\Policy)}_{m,j}(0,t,n)
    },
\end{align}
where
{\small
\begin{align}
    \hat{\theta}^{(k,\Policy)}_{m,j}(\xi,t,n) \define
    \begin{cases}
        \lambda_{k,j} I[\omega_{k,j}(t)=m], &\xi=0, n < \mathcal{D}_{k}(t)
        \\
        \lambda_{k,j} I[\omega_{k,j}(t+1)=m], &\xi=0, n \geq \mathcal{D}_{k}(t) 
        \\
        \Pr\{R^{(k)}_{m,j}(\xi,t,n)=1\}, & \text{otherwise}
    \end{cases}.
\end{align}
}
The dispatching policy $\Policy$ only affects the first entry of the probability vector, i.e. the arrival probability of one job in the time slot.
Hence, we denote the time-invariant transition matrix $\hat{\Gamma}^{(k)}_{m,j}$ for the state transition on AP between adjacent time slots which is defined as follows.
\begin{align}
    \hat{\Gamma}^{(k)}_{m,j} &\define
    \begin{bmatrix}
        1 & \bar{p}^{(k)}_{m,j,0} &                       &        &                           \\
        & 0                     & \bar{p}^{(k)}_{m,j,1} &        &                           \\
        &                       & \ddots                & \ddots &                           \\
        &                       &                       & \ddots & \bar{p}^{(k)}_{m,j,\Xi-1} \\
        &                       &                       &        & 0                         \\
    \end{bmatrix},
\end{align}
where $\bar{p}^{(k)}_{m,j,\xi}$ denotes the probability of job still stay at the $k$-th AP in the next time slot as $\bar{p}^{(k)}_{m,j,\xi} = 1 - p^{(k)}_{m,j,\xi}$, and
\begin{align}
    p^{(k)}_{m,j,\xi} &\define \Pr\{U^{(k)}_{m,j} < (\xi+1) | U^{(k)}_{m,j}>\xi\}
\end{align}
denotes the probability of job offloading to the $m$-th edge server.
% And we note that $\theta^{(k)}_{m,j,0}(t,n)$ is purely determined by the arrival process and dispatching policy of the $j$-th type of job on the $k$-th AP, i.e. $\theta^{(k)}_{m,j,0}(t,n) = \lambda_{k,j} I[\omega_{k,j}(t) = m]$.

Hence, let $\vecG{\Theta}^{(\Policy, k)}_{m,j}(t)$ and $\Gamma^{(k)}_{m,j}$ denotes the probability vector and transition matrix for the adjacent broadcast interval, respectively.
Based on the previous definition in the time slot, the explicit definition is given as follows.
\begin{align}
    \vecG{\Theta}^{(\Policy, k)}_{m,j}(t) &\define \hat{\vecG{\Theta}}^{(\Policy, k)}_{m,j}(t,0)
    \\
    \vecG{\Theta}^{(k)}_{m,j}(t+1) &= \hat{\vecG{\Theta}}^{(k)}_{m,j}(t, \mathcal{D}_{k}(t)) \times (\hat{\Gamma}^{(k)}_{m,j})^{N-\mathcal{D}_{k}(t)},
    \nonumber\\
    \hat{\vecG{\Theta}}^{(k)}_{m,j}(t, \mathcal{D}_{k}(t)) &= \vecG{\Theta}_{m,j}(t) \times (\hat{\Gamma}^{(k)}_{m,j})^{\mathcal{D}_{k}(t)}.
\end{align}


% is composed of two-phase policy separated by $D_k(t)$, which is expressed as follows.
% \begin{align}
%     \vecG{\Theta}^{(k)}_{m,j}(t, \mathcal{D}_{k}(t)) &= (\Gamma^{(k)}_{m,j})^{\mathcal{D}_{k}(t)} \times \hat{\vecG{\Theta}}_{m,j}(t),
%     \nonumber\\
%     \hat{\vecG{\Theta}}^{(k)}_{m,j}(t+1) &= (\Gamma^{(k)}_{m,j})^{N-\mathcal{D}_{k}(t)} \times \vecG{\Theta}^{(k)}_{m,j}(t, \mathcal{D}_{k}(t)).
% \end{align}
Given that the cost raised on APs is approximated with baseline policy $\Baseline$, the AP (saying the $k$-th AP) would adopt the same dispatching actions as $\Baseline(\Stat(t))$ before and after $\mathcal{D}_{k}(t)$ time slots in the $t$-th broadcast interval.
Hence, we have
\begin{align}
    \vecG{\Theta}^{(k,\Baseline)}_{m,j}(t+1) = \vecG{\Theta}^{(k,\Baseline)}_{m,j}(t) \times (\hat{\Gamma}^{(k)}_{m,j})^{N}.
\end{align}

Then, we could express the cost raised on AP under baseline policy $\Baseline$ as follows.
\begin{align}
    &\tilde{W}^{\AP}_{k,m,j}\Paren{\Stat(t+1)} =
    \Inorm{
        \Bracket{
            \vecG{\Theta}^{(k, \Baseline)}_{m,j}(t+1)
        }'
        \Bracket{
            \mat{I} - \gamma \Gamma^{(k)}_{m,j}
        }^{-1}
    }.
    \label{w_ap}
\end{align}


%NOTE: transition matrix and vector for ES
\section{ Proof of Lemma \ref{lemma:w_es} }
\label{append_2}
%NOTE: small probability approximation
% The expression of transition matrix $P_{m,j}$ is more complex.
% The expression for expected value function is little more complex compared to equation (\ref{w_ap}).
    % The transition matrix for state transition is affected by the baseline policy and the system states of APs.
    % However, we notice that under the fixed baseline policy, the arrival process on edge servers would be stationary after the maximum uploading time from the initial interval, and thus the transition matrix is invariant of system states of APs.
    % Let $\mat{P}_{m,j}(\Baseline_{t})$ be the transition matrix under baseline policy $\Baseline_{t}$ which is invariant of system states of APs 
The transition happening on edge servers is affect by the arrival process from APs.
Hence, we first denote the offloading matrix $\bar{\Gamma}^{(k)}_{m,j}$ from each AP to the $m$-th edge server and the offloading number vector $\vecG{\rho}^{(k,+)}_{m,j}({t,n})$ as follows, respectively ($\forall k\in\apSet, m\in\esSet_{m}, j\in\jSpace$).
\begin{align}
    \bar{\Gamma}^{(k)}_{m,j}(t,n) &\define
    \begin{bmatrix}
        0 & p^{(k)}_{m,j,0} &                 &        &                     \\
        & 0               & p^{(k)}_{m,j,1} &        &                     \\
        &                 & \ddots          & \ddots &                     \\
        &                 &                 & \ddots & p^{(k)}_{m,j,\Xi-1} \\
        &                 &                 &        & 1                   \\
    \end{bmatrix},
    \\
    \vecG{\rho}^{(k,+)}_{m,j}({t,n}) &\define \bar{\Gamma}^{(k)}_{m,j} \times \vecG{\theta}^{(k)}_{m,j}({t,n}).
\end{align}
The combinations of all the offloading number vector for the $m$-th edge server from its \emph{potential AP set} would be unacceptable.
Thus we rewrite the arrival process on edge server with small probability approximation, i.e. there would be at most one job arriving in one time slot, with the probability as the expected arrival rate of the original distribution.
The explicit definition of the approximate arriving probability $\beta_{m,j}({t,n})$ is given as follows.
\begin{align}
    {\beta}_{m,j}({t,n}) &\define \sum_{k\in\apSet} \sum_{\xi=0,\dots,\Xi-1} \mathbb{E}[\vecG{\rho}^{(k,+)}_{m,j,\xi}({t,n})]
    \label{eqn_0}
\end{align}
\begin{lemma}[Small Probability Approximation]
    The probability distribution of $\sum_{k\in\apSet} \vecG{\rho}^{(k,+)}_{m,j}({t,n})$ could be approximated with a Bernoulli arrival process who is with the expected arrival rate denoted as ${\beta}_{m,j}({t,n})$.
\end{lemma}
\begin{proof}
    % We notice that the job arrival distribution ${\beta}_{m,j}(t)$ is given by $\mathcal{R}(t)$, and the departure rate in one slot is deterministic as $1/N$.
    % Thus the expectation of ${\beta}$ would be always far more smaller than $1$ as composed of all $K$ AP nodes.
    % We take approximation on ${\beta}$ as Bernoulli distribution in each time slot.
\end{proof}

%NOTE: transition matrix and vector for Edge Server
Thus we could obtain the denotation of transition matrix and probability vector for edge servers.
\begin{definition}[Denotation of Transition on Edge Server]
    Let $\vecG{\mu}_{m,j}(t,n)$ and $P_{m,j}$ denote the probability vector and transition matrix of $Q_{m,j}(t,n)$ at the $n$-th time slot in the $t$-th broadcast interval, respectively ($\forall m\in\esSet, j\in\jSpace$).
    \begin{align}
        \vecG{\mu}_{m,j}(t,n) \define [\Pr\{Q_{m,j}(t,n)=0\}, \dots, \Pr\{Q_{m,j}(t,n)=L_{max}\}].
    \end{align}

    Let $\hat{\vecG{\nu}}_{m,j}(t)$ denote the probability vector at the first time slot of the $t$-th broadcast interval.
    The time-variant transition matrix composed of multiple transition matrix $\mat{\hat{P}}_{m,j}(\beta({t,n}))$ in all the time slots in $i$-th interval as follows.
    \begin{align}
        \hat{\vecG{\nu}}({t,n+1}) &= \mat{\hat{P}}_{m,j}\Paren{\beta_{m,j}({t,n})} \hat{\vecG{\nu}}({t,n})
        % \label{eqn_3}
        \\
        \vecG{\nu}(t+1) &= \prod_{n=0,\dots,N-1} \mat{\hat{P}}_{m,j}\Paren{\beta_{m,j}({t,n})} \vecG{\nu}(t),
        \label{eqn_4}
    \end{align}
\end{definition}

%----------------------------------------------------------------------------------------%
%----------------------------------------------------------------------------------------%
\delete{v19}{
    Firstly, we notice that the transition function in equation (\ref{eqn:sp_0}) could be rewritten in the following form.
    \begin{align}
        & \Pr\Brace{ \Stat(t+1)|\Stat(t), \Policy(\Stat(t)) }
        \nonumber\\
        =& \prod_{j\in\jSpace} \Brace{
            \prod_{k\in\apSet} \prod_{m\in\esSet}
            \Pr\big\{
                \vec{R}^{(k)}_{m,j}(t+1) | \vec{R}^{(k)}_{m,j}(t), \Policy(\Stat(t))
            \big\}
            \nonumber\\
            &\times \prod_{m\in\esSet} \Pr\big\{
                Q_{m,j}(t+1) | Q_{m,j}(t), \Policy(\Stat(t))
            \big\}
        },
    \end{align}
    where the two production parts denote state transition on APs and edge servers under policy $\Policy$, respectively.
}