
\section{Introduction}
%NOTE: General Background of MEC and Motivation
Edge computing is believed to be a promising solution for increasing computation-intensive and energy-hungry applications on mobile devices.
Large amount of mobile devices can connect to the access points (APs) which functions as gateway to aggregate and offload jobs to the edge servers \cite{MEC-SURVEY}.
The edge servers are deployed in closer proximity to APs than cloud infrastructure, which alleviates the communication overhead and enables offloading of time-sensitive jobs.
However, the edge servers are always deployed with limited computation resources.
The establishment of efficient cooperation among APs and edge servers is one of the major design challenges, given the network transmission latency and signaling overhead.

%NOTE: Motivation with MAN
We consider an edge computing system with multiple APs and edge servers residing in the Metropolitan Area Network (MAN).
The APs should collect jobs offloaded from the mobile users in its service area and make dispatching decisions for each job.
The existing literature, such as \cite{tan-online,MOBIHOC19-ZhouZ,IOTJ18-FanQ,TOC19-LiuC,JSAC19-AlameddineHA}, usually assumed that the transmission latency of jobs is non-negligible but fixed in MAN.
However, according to the MAN performance analysis research in \cite{MAN-LATENCY}, the transmission latency will vary a lot with respect to different hours of day and devices' locations in a MAN.
This brings new challenges to the job dispatcher design in the edge computing network.
Firstly, the centralized dispatcher design is discouraged with outdated system information and unpredictable signaling latency.
% Secondly, the staleness of information is not negligible and the outdated information received by dispatcher would cause mis-estimate of system states which results into irreversible error.
% Last but not the least, the cooperation of distributive dispatchers requires sharing utility function according to \cite{IJCAI03-NairR} and the observed information from different dispatchers is not identical all the time.
Secondly, the cooperation of distributive dispatchers suffers from significant signaling overhead and the random transmission latency causes the inconsistency of system information at different dispatchers.

%NOTE: Our contributions
In this paper, we would like to shed some lights on the above challenging distributive dispatcher design via POMDP problem formulation and a novel low-complexity approximate MDP solution framework.
Specifically, the signaling latency among APs and edge servers and job uploading latency from APs to edge servers are assumed to be random, and our contributions in this new optimization scenario are summarized as follows.
\begin{itemize}
    \item We propose a novel low-complexity distributive solution framework for the dispatcher design at the APs, where each AP collects the information only from the APs and edge servers in a close proximity and make dispatching decision with random signaling latency. We directly derive the expression of approximate value function and obtain distributive dispatching policy via one-step policy iteration. Thus, the complicated POMDP solution or value iteration is avoided. To our best knowledge, this is the first work to address the cooperative distributive multi-agent optimization problem under MDP framework.
    \item We derive an analytical cost lower bound for the proposed distributive dispatching policy in the above novel solution framework. In the conventional approximate MDP method, the performance is usually evaluated via numerical method, and it is hard to obtain analytical performance bound.
\end{itemize}

The remainder of this paper is organized as follows.
In Section \ref{sec:review}, we review on the related works.
In Section \ref{sec:model}, we illustrate the system model and broadcast information sharing design.
In Section \ref{sec:formulation}, we formulate the global optimization problem of joint optimization on dispatching decisions of all APs.
In Section \ref{sec:algorithm}, we argue that the global joint optimization of all APs is impractical and then decouple the problem into optimization over individual APs.
We introduce a low-complexity algorithm in Section V and then show the numerical analysis in Section \ref{sec:evaluation}.
In Section \ref{sec:conclusion}, the conclusion is given.

\section{Related Works}
\label{sec:review}
%NOTE: resource placement (cache-like problem), service migration
The recent academic works of scheduling problem in edge computing system focus on the resource allocation, job dispatching, service migration and etc.
The service migration problem is addressed that the jobs submitted to the edge server could be further migrate to other edge servers if the QoS of the job could not be satisfied.
For example, the authors in \cite{TON19-WangSq} consider the edge server is one-to-one bind to the base station (BS), and the job migration could be applied according to users' mobility traces via the backhaul network connecting the base stations.
However, according to a recent research \cite{INFOCOM19-WuC}, the resource re-allocation for running jobs on servers is hard to implement in practice, and thus it's hard for jobs migration among heterogeneous edge servers with different resource configurations.
Hence, it's more important to determine the job dispatching strategy at the arrival time.

%NOTE: single-agent dispatching, single UE/server
% The resource allocation problem is always joint optimization together with job offload problem, including bandwidth resources, computation resources, and etc.
The job dispatching problem in the edge computing system often consists of the following components: mobile users (MU), access points (APs) and edge servers, where APs would collect the jobs offloaded from MUs in its coverage and offload them to the edge servers via the wired network.
We denote the role which makes job dispatching decisions as \emph{agent} in the remaining of the paper.
In \cite{tan-online}, the authors formulate the problem with $K$ heterogenous edge-cloud servers located in MAN and assume fixed deterministic offloading latency.
A heuristic algorithm is proposed to minimize the average job response time.
The authors in \cite{IOTJ18-FanQ} consider the setting where base stations (BSs) and edge servers connected via SDN in the cellular core network, and propose a heuristic algorithm to offload the jobs to the closest cloudlets firstly.
In \cite{MASS18-MengZ}, the authors formulate the offloading problem considering edge and cloud servers as integer linear programming with fixed deterministic offloading latency.
The above works all considered the optimization problem from jobs' perspective, and did not specify the \emph{agent} to apply the dispatching decisions by solving the problem.
However, in practice, it's important to specify whether the \emph{agent} is implemented in a centralized or distributive form.

% Here, we only stress the problem happened between APs and edge servers which is connected via wired network.
% When the dispatching decisions of multiple users/APs are considered, the information exchange scheme should be designed.

%NOTE: centralized and distributive multi-agent related works
There are some work considering a centralized agent is implemented to apply dispatching decisions for multiple APs.
In \cite{IOTJ19-CaoJ}, the authors have one extra dispatch server in the system to queue the offloading jobs and then dispatch them to the edge servers.
It's obvious that the extra dispatcher design introduces unnecessary transmission latency.
In \cite{Fan2017}, the authors consider the cooperation of multiple MEC-BSs of computation offloading to other MEC-BSs. However, it doesn't consider the offloading utility impact on other MEC-BSs, i.e. only optimize for one BSs in the cluster.
In \cite{JSAC19-AlameddineHA}, the authors consider edge server is one-to-one bind to eNB in smart city wide area network (WAN), and centralized make decision with SDN controllers which has a global view of the network.
In \cite{TVT19-WangY}, the authors propose full cooperation of the edge servers and the cloud server as mixed integer nonlinear optimization problem (MINLP).
The authors proposed a parallel optimization scheme where a master computation unit is utilized to collect the global variables from the edge servers and the cloud server without delay. 
However, in the above works, the delay information in the system is known as fix constant, and the information exchange latency is ignored.

% There are also some works considering distributive multi-agent scheduling where the information exchange scheme matters.
% In \cite{CloudCom18-Cicconetti},

%NOTE: stale-information based multi-agent related works
Different from the previous referred works which merely consider the information exchange latency in the system, the staleness of exchanged information sharing among agents also have impacts on decision making in distributive system.
As what we have learned, there are very limited discussions on this topic.
% The earliest works entangling with outdated information we could find is \cite{ref-01} (cited 167 times). In this work, the single agent is assumed not able to observe the global state, and thus they need communication to establish cooperation by sharing limited information. The agent considers communication as extra action to synchronize the states and thus incurs extra cost (However, the communication is without delay, thus converted into POMDP problem; criticize with impractical);
In \cite{JSAC17-LyuX}, the authors consider maximizing the number of admitted jobs where jobs offloading via base stations with stochastic offloading latency with general time-division multiple-access (TDMA) model assumption.W
The \emph{partial outdated knowledge} is introduced that the agents share the backlog information continuously in each time slot but some are missing in the transmission which is taken as \emph{outdated knowledge}.
The author leverage Lyapunov optimization to obtain a randomized fixed policy which could eliminate the staleness introduced, while the stability of the queues on edge servers is guaranteed. 
In \cite{TWC18-LyuX}, the authors move on considering selfish devices offloading jobs with stale information.
The problem is formulated to minimize the overall energy consumption while stabilizing the queues.
% The optimality loss due to the information staleness is proved bounded and can diminish to preserve the asymptotic optimality.
However, in the above two works, the queueing process on edge servers is not analyzed.
Due to the chosen objectives with only queue-stability guarantee, the upper bound of queue length could be very loose and could not guarantee the real-time performance of offloaded jobs.
Hence, in our problem, we target at optimizing the average job response time while analyzing the queueing process on edge servers under random uploading distribution and dispatching decisions to be optimized.

%NOTE: deleted references with wireless resource allocation
% In \cite{TOC18-LyuX}, the authors optimize the job admission with partial observed information to assure the asymptotic optimality while the staleness is eliminated.
% However, the staleness of information gap could not be eliminated in complex fully-cooperative scenario, where all the agents share the same utility function to optimize.
% The authors in \cite{TOC17-DinhTQ} consider job dispatching only with single MU in the system.
% Specifically, the authors consider jointly energy and latency optimization with one Mobile Device (MD) by offloading the jobs to multiple servers in \cite{TOC17-DinhTQ}
% \cite{MOBIHOC19-LiuQ} is a work with centralized controller which determine the radio resources and computing resources for network slices on edge servers.
% \cite{ACCESS19-ZhengX} is a work considering maximizing the long-term utility in MEC offloading policy, and formulating the problem with MDP solved with Q-learning.
% However, it is applied with a centralized controller which is assumed without communication overhead the Q-learning method could not guarantee the performance before its convergence.
% The information exchange is implement via query and the authors evaluate how the query interval affects the convergence of the algorithm.

%----------------------------------------------------------------------------------------%
\delete{v11}{
    \cite{Naha2018} is a survey about fog computing in delay-aware computing in IoT, and investigate numerous proposed computing architecture.

    Service Placement Scenario:
    \begin{itemize}
        \item \cite{Rodrigues2017} is a work on minimizing service delay in mobile edge computing;
        \item \cite{Yang2016} is a work considering services placement and requests dispatching on edge servers, and leverage users' pattern to predict "service cache" for online decision making;
        \item \cite{Chen2018} is a work with SDN on task offloading and battery life saving, and solve the NLP problem with two sub-problems;
    \end{itemize}
    Using Game Theory:
    \begin{itemize}
        \item \cite{yang2018} and \cite{Josilo2019a} considers distributive computation offloading game;
        \item \cite{Liu2018} is a work considering minimize users' power consumption with Lyapunov optimization and matching theory;
        \item \cite{Dinh2018} considers distributive multi-user offloading in wireless channel with selfish EPG (exact potential game);
        \item \cite{Josilo2019} considers selfish offloading to achieve Nash equilibrium;
        \item \cite{Chen2016} is a work considering multi-user computation offloading with multi-channel contention, and adopt game theory approach to achieve Nash equilibrium with upper bound of convergence time;
        \item \cite{Zhang2018} considers multi-user offloading under transmit power decision and user association decision;
    \end{itemize}
    System Work:
    \begin{itemize}
        \item \cite{Yu2018} is a system work published in ToMC, presents a framework to minimize remote execution overhead, and carry out real system experiments using large-scale data from cellular network provider;
        \item \cite{Wang2018} is a system work published in IEEE Access, considers the mobility of mobile users in limited coverage solved with service migration and handover, and propose a framework;
    \end{itemize}
}