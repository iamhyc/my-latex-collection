\section{Performance Evaluation}
\label{sec:evaluation}
\subsection{Parameter Settings}
\begin{figure*}[htp!]
    \centering
    \begin{tabular}{ccc}
        \includegraphics[width=0.30\textwidth]{images/535_LowPressure_NoDelay.pdf}&
        \includegraphics[width=0.30\textwidth]{images/535_LowPressure_LargeDelay_cdf.pdf}&
        \includegraphics[width=0.30\textwidth]{images/535_LowPressure_FullDelay.pdf}
        \\
        {\small (a) No \brlatency} &
        {\small (b) Large \brlatency} &
        {\small (c) Whole-interval \brlatency}
    \end{tabular}
    \caption{Evaluation of Information Staleness Impact on Algorithm Robustness under Low Back Pressure.}
    \label{fig:eval_delay}
\end{figure*}

\begin{itemize}
    \item \comments{Small scale setting with fully-connected APs and edge server with:} $K=5$ APs, $M=3$ edge servers, and $J=5$ types of jobs;
    \item Each time slot with $\tau=0.05$ s (a.k.a $50$ ms), and broadcast interval $T=N \cdot \tau$ with $N=30$;
    \item The maximum uploading time is $\Xi = 3 T$, and the \brlatency is shorter than $t_B$;
    \item (arrival rate is random generated as $\lambda_{k,j} \ll 1/N$)
    \item job processing time distribution generated from real data trace;
    \item Each queue on edge server with maximum 10 jobs.
\end{itemize}

Specifically, we choose a heuristic selfish policy as the start and the definition is given as follows.
\begin{definition}[Selfish Policy]
    \begin{align}
        \Baseline &\define \Bracket{ \Pi_{1}, \dots, \Pi_{K} }
        \\
        \pi_{k,j} &\define \arg\min_{m} \mathbb{E}[U_{k,m,j}] + \mathbb{E}[C_{m,j}]
    \end{align}
\end{definition}

We compare the proposed algorithm with other three heuristic algorithms.
Compared Algorithm:
\begin{itemize}
    \item \textbf{Random Dispatching Policy}:
            randomly dispatch jobs to edge servers;
    \item \textbf{Local Selfish Algorithm (baseline policy)}:
            always choose the edge server with the minimum expected uploading time plus the expected processing time for each job type; this policy is also taken as the initial fixed policy of our proposed algorithm;
    \item \textbf{Local Queue-aware Greedy Algorithm}:
            always choose the edge server with the minimum expected uploading time, plus the expected queueing time based on the observation of stale queue state.
\end{itemize}

% [abandon, cause useless]
% \subsection{Estimation Error Analysis}
% (If these graphs are not good, they are not going to appear on final draft.)
% \begin{itemize}
%     \item Two curves, one for real cost against time slot, one for expected sampling cost against time intervals; (if the accumulate area within the latter one has little/bounded error with real cost, then it is okay and the correctness is support by simulation)
%     \item 
% \end{itemize}

\subsection{Performance Analysis}
Compared with different parameter settings:
\begin{itemize}
    \item CDF of cost (Average JCT), with different broadcast $t_B$ setting;
    \item CDF of cost (Average JCT), with different \brlatency $D_{i,k}$ setting;
\end{itemize}

Compared with other algorithms:
\begin{itemize}
    \item CDF of cost (Average JCT);
    \item CDF of queue length;
    \item CDF of \# of dropped jobs (over the queue limit);
\end{itemize}